{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9876b973",
   "metadata": {},
   "source": [
    "# Memory Optimization Guide for Binary Neural Networks with 224x224 Images\n",
    "\n",
    "This notebook contains a comprehensive collection of memory optimization techniques for training Binary Neural Networks (BNNs) with 224x224 images on systems with limited GPU memory.\n",
    "\n",
    "## Quick Start Guide\n",
    "\n",
    "1. Set your dataset path in the \"Set Dataset Path\" cell\n",
    "2. Choose a memory optimization strategy:\n",
    "   - **Strategy A**: Use the ConvBNN224x224 model for full 224x224 resolution\n",
    "   - **Strategy B**: Use feature extraction with a pre-trained model\n",
    "   - **Strategy C**: Use patch-based processing\n",
    "   - **Strategy D**: Use layer-freezing techniques\n",
    "\n",
    "3. Run the complete recipe in the final cell\n",
    "\n",
    "## Memory Optimization Techniques in this Notebook\n",
    "\n",
    "- **Aggressive Memory Settings**:\n",
    "  - Low batch size with gradient accumulation\n",
    "  - Garbage collection after each batch\n",
    "  - Reduced worker threads\n",
    "  - Disabled pin memory\n",
    "\n",
    "- **Model Architecture Optimizations**:\n",
    "  - Binary activations and weights\n",
    "  - Progressive dimensionality reduction\n",
    "  - Convolutional feature extraction\n",
    "  - Gradient checkpointing\n",
    "  - Depthwise separable convolutions\n",
    "\n",
    "- **Training Process Optimizations**:\n",
    "  - Mixed precision training\n",
    "  - Sample limiting per class\n",
    "  - Feature pre-extraction\n",
    "  - Patch-based processing\n",
    "  - Model compression techniques\n",
    "\n",
    "Choose the techniques that work best for your specific hardware limitations while maintaining the desired 224x224 image resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c52d01",
   "metadata": {},
   "source": [
    "# Memory-Efficient Binary Neural Network (BNN) for Plant Disease Classification - 224x224 Images\n",
    "\n",
    "This notebook implements a Binary Neural Network using PyTorch for multiclass plant disease classification, optimized for handling 224x224 images on GPUs with limited memory.\n",
    "\n",
    "## Memory Management Guide\n",
    "\n",
    "This notebook has been optimized for running on GPUs with limited memory (under 4GB). The settings have been automatically adjusted to \"aggressive\" mode to prevent CUDA out-of-memory errors.\n",
    "\n",
    "### Current Memory-Optimized Settings:\n",
    "- Image resolution: 224x224 (standard image size)\n",
    "- Batch size: 4 (reduced for memory efficiency)\n",
    "- Hidden size: 256 (compact model architecture)\n",
    "- Progressive dimensionality reduction (multiple embedding steps)\n",
    "- Gradient accumulation: 8 steps (effective batch size of 32)\n",
    "- Mixed precision training (FP16)\n",
    "\n",
    "### Memory Monitoring\n",
    "You can monitor GPU memory usage by checking the output of the memory monitoring tools included at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b2c25",
   "metadata": {},
   "source": [
    "# Binary Neural Network (BNN) for Plant Disease Classification\n",
    "\n",
    "This notebook implements a Binary Neural Network using PyTorch for multiclass plant disease classification. The BNN uses binary weights and activations to reduce model size and computational requirements while maintaining reasonable accuracy.\n",
    "\n",
    "## Features:\n",
    "- Binary weights and activations using sign function\n",
    "- Processes 224x224 RGB images (standard size)\n",
    "- Progressive dimensionality reduction for memory efficiency\n",
    "- Binary hidden layers with binary weights\n",
    "- Batch normalization for improved stability\n",
    "- Dropout for regularization\n",
    "- Learning rate scheduling for better convergence\n",
    "- Multiclass output with softmax activation\n",
    "- Mixed precision training\n",
    "- Gradient accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7959b614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PyTorch version: 2.7.1+cu126\n",
      "Applied extreme memory optimization settings\n",
      "Memory Configuration Mode: High Memory Optimization (224x224)\n",
      "Batch Size: 1\n",
      "Gradient Accumulation Steps: 8\n",
      "Effective Batch Size: 8\n",
      "GC Frequency: 1\n",
      "Memory Efficient: True\n",
      "Mixed Precision: True\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, Subset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# Check for CUDA availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# # Memory configuration - optimized for large images (224x224)\n",
    "# memory_config = {\n",
    "#     'batch_size': 1,  # Smaller batch size for larger images\n",
    "#     'gradient_accumulation_steps': 4,  # Accumulate gradients over multiple batches\n",
    "#     'gc_frequency': 5,  # Garbage collection frequency\n",
    "#     'memory_efficient': True,  # Use memory-efficient techniques\n",
    "#     'use_mixed_precision': True  # Use mixed precision training if available\n",
    "# }\n",
    "\n",
    "# Updated memory configuration with extreme optimization\n",
    "memory_config = {\n",
    "    'batch_size': 1,  # Absolute minimum\n",
    "    'gradient_accumulation_steps': 8,  # Increase to compensate for tiny batch\n",
    "    'gc_frequency': 1,  # Maximum GC\n",
    "    'memory_efficient': True,\n",
    "    'use_mixed_precision': True,\n",
    "    'image_size': 128,  # Reduced image size\n",
    "    'hidden_size': 128,  # Smaller model\n",
    "    'embedding_size': 256,  # Smaller embeddings\n",
    "    'max_samples_per_class': 50,  # Limit dataset size temporarily\n",
    "    'num_workers': 0,  # No parallel data loading\n",
    "    'pin_memory': False  # Disable pin memory\n",
    "}\n",
    "\n",
    "print(\"Applied extreme memory optimization settings\")\n",
    "\n",
    "# Use memory configuration\n",
    "batch_size = memory_config['batch_size']\n",
    "gradient_accumulation_steps = memory_config['gradient_accumulation_steps'] \n",
    "gc_frequency = memory_config['gc_frequency']\n",
    "memory_efficient = memory_config['memory_efficient']\n",
    "use_mixed_precision = memory_config['use_mixed_precision']\n",
    "memory_mode = 'High Memory Optimization (224x224)'\n",
    "\n",
    "print(f\"Memory Configuration Mode: {memory_mode}\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Gradient Accumulation Steps: {gradient_accumulation_steps}\")\n",
    "print(f\"Effective Batch Size: {batch_size * gradient_accumulation_steps}\")\n",
    "print(f\"GC Frequency: {gc_frequency}\")\n",
    "print(f\"Memory Efficient: {memory_efficient}\")\n",
    "print(f\"Mixed Precision: {use_mixed_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f9c03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpointing available - will use to save memory\n",
      "\n",
      "Current GPU memory usage:\n",
      "- Allocated: 0.000 GB\n",
      "- Reserved:  0.000 GB\n"
     ]
    }
   ],
   "source": [
    "# EXTREME MEMORY OPTIMIZATION\n",
    "# Run this cell if you are still facing memory issues\n",
    "\n",
    "# 1. Force CPU-only mode (completely bypass GPU)\n",
    "# Uncomment this line to force CPU mode\n",
    "# device = torch.device(\"cpu\")\n",
    "# print(f\"FORCED CPU MODE: {device}\")\n",
    "\n",
    "# 2. More extreme memory config\n",
    "extreme_memory_config = {\n",
    "    'batch_size': 1,\n",
    "    'gradient_accumulation_steps': 8,\n",
    "    'gc_frequency': 1,\n",
    "    'memory_efficient': True,\n",
    "    'use_mixed_precision': False,  # Mixed precision might not work well on CPU\n",
    "    'image_size': 64,  # Drastically reduced image size\n",
    "    'hidden_size': 64,\n",
    "    'embedding_size': 128,\n",
    "    'max_samples_per_class': 20,  # Ultra-limited dataset size\n",
    "    'num_workers': 0,\n",
    "    'pin_memory': False,\n",
    "    'num_hidden_layers': 1,  # Minimum layers\n",
    "    'dropout_rate': 0.5,  # More aggressive dropout\n",
    "}\n",
    "\n",
    "# To use these extreme settings, uncomment the next line:\n",
    "# memory_config = extreme_memory_config\n",
    "# print(\"⚠️ EXTREME memory optimization settings applied!\")\n",
    "\n",
    "# 3. Enable model checkpointing\n",
    "try:\n",
    "    from torch.utils.checkpoint import checkpoint\n",
    "    use_checkpointing = True\n",
    "    print(\"Checkpointing available - will use to save memory\")\n",
    "except ImportError:\n",
    "    use_checkpointing = False\n",
    "    print(\"Checkpointing not available in this PyTorch version\")\n",
    "\n",
    "# 4. Empty CUDA cache more aggressively\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# 5. Display current GPU memory status\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nCurrent GPU memory usage:\")\n",
    "    print(f\"- Allocated: {torch.cuda.memory_allocated() / (1024**3):.3f} GB\")\n",
    "    print(f\"- Reserved:  {torch.cuda.memory_reserved() / (1024**3):.3f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bd0a2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU memory usage before optimizations:\n",
      "- Allocated: 0.000 GB\n",
      "- Reserved: 0.000 GB\n"
     ]
    }
   ],
   "source": [
    "# 224x224-SPECIFIC MEMORY OPTIMIZATIONS\n",
    "# This cell provides optimizations while keeping 224x224 image size\n",
    "\n",
    "# 1. Update memory config for 224x224 specifically\n",
    "memory_config_224 = {\n",
    "    # Keep the 224x224 image size\n",
    "    'image_size': 224,\n",
    "    \n",
    "    # Data loading optimizations\n",
    "    'batch_size': 1,  # Absolute minimum\n",
    "    'gradient_accumulation_steps': 32,  # Very high accumulation to compensate for batch=1\n",
    "    'max_samples_per_class': 20,  # Very limited samples\n",
    "    'num_workers': 0,\n",
    "    'pin_memory': False,\n",
    "    \n",
    "    # Memory aggressive settings\n",
    "    'gc_frequency': 1,  # Run GC after every batch\n",
    "    'memory_efficient': True,\n",
    "    'use_mixed_precision': True,\n",
    "    \n",
    "    # More conservative model architecture\n",
    "    'hidden_size': 64,  # Drastically reduced\n",
    "    'embedding_size': 128,  # Drastically reduced\n",
    "    'num_hidden_layers': 1,\n",
    "}\n",
    "\n",
    "# Uncomment to apply 224x224 specific settings\n",
    "# memory_config.update(memory_config_224)\n",
    "# print(\"Applied 224x224-specific memory optimizations\")\n",
    "\n",
    "# 2. Set PYTORCH_CUDA_ALLOC_CONF for more aggressive memory management\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True,max_split_size_mb:32'\n",
    "\n",
    "# 3. Enable gradient checkpointing (requires PyTorch >= 1.4)\n",
    "USE_GRADIENT_CHECKPOINTING = True\n",
    "\n",
    "# 4. Empty cache before starting\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# 5. Display current memory usage\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU memory usage before optimizations:\")\n",
    "    print(f\"- Allocated: {torch.cuda.memory_allocated() / (1024**3):.3f} GB\")\n",
    "    print(f\"- Reserved: {torch.cuda.memory_reserved() / (1024**3):.3f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1678596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results directory created: ./results/\n"
     ]
    }
   ],
   "source": [
    "# Additional imports for enhanced visualization and data export\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs('results', exist_ok=True)\n",
    "print(\"Results directory created: ./results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72438200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bnn_memory_efficient(model, test_loader, criterion, device, class_names, batch_limit=None, use_mixed_precision=False):\n",
    "    \"\"\"\n",
    "    Memory-efficient evaluation function for BNN model\n",
    "    \n",
    "    Args:\n",
    "        model: The trained BNN model\n",
    "        test_loader: DataLoader for the test dataset\n",
    "        criterion: Loss function\n",
    "        device: Device to run evaluation on\n",
    "        class_names: List of class names\n",
    "        batch_limit: Limit the number of batches to evaluate (for debugging)\n",
    "        use_mixed_precision: Whether to use mixed precision\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with evaluation metrics\n",
    "    \"\"\"\n",
    "    # Import needed modules at the beginning of the function to avoid UnboundLocalError\n",
    "    import torch\n",
    "    import torch.nn.functional as F\n",
    "    import time\n",
    "    import contextlib\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Set up metrics\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Initialize confusion matrix\n",
    "    num_classes = len(class_names)\n",
    "    confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "    \n",
    "    # Prepare for per-class metrics\n",
    "    class_correct = [0] * num_classes\n",
    "    class_total = [0] * num_classes\n",
    "    \n",
    "    # Set up for precision, recall, F1\n",
    "    true_positives = [0] * num_classes\n",
    "    false_positives = [0] * num_classes\n",
    "    false_negatives = [0] * num_classes\n",
    "    \n",
    "    # Store some sample images for visualization\n",
    "    sample_images = []\n",
    "    sample_labels = []\n",
    "    sample_preds = []\n",
    "    samples_collected = 0\n",
    "    max_samples = 10  # Maximum number of samples to collect\n",
    "    \n",
    "    # For ROC curve\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "    \n",
    "    # Check if mixed precision is available\n",
    "    mixed_precision_available = use_mixed_precision and hasattr(torch, 'autocast')\n",
    "    \n",
    "    # Determine the appropriate autocast context manager based on PyTorch version\n",
    "    if mixed_precision_available:\n",
    "        try:\n",
    "            from torch.cuda.amp import autocast\n",
    "            # Check if the version supports device_type parameter\n",
    "            torch_version = torch.__version__\n",
    "            supports_device_type = int(torch_version.split('.')[0]) >= 1 and int(torch_version.split('.')[1]) >= 10\n",
    "            \n",
    "            # Define context manager with appropriate parameters\n",
    "            if supports_device_type:\n",
    "                autocast_context = lambda: autocast(device_type=device.type)\n",
    "            else:\n",
    "                # Older PyTorch versions only support CUDA and don't need device_type\n",
    "                autocast_context = lambda: autocast()\n",
    "        except ImportError:\n",
    "            try:\n",
    "                from torch.amp import autocast\n",
    "                autocast_context = lambda: autocast(device_type=device.type)\n",
    "            except ImportError:\n",
    "                mixed_precision_available = False\n",
    "                autocast_context = contextlib.nullcontext\n",
    "    else:\n",
    "        autocast_context = contextlib.nullcontext\n",
    "\n",
    "    # Track processing time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Disable gradient computation for evaluation\n",
    "    with torch.no_grad():\n",
    "        # Process batches\n",
    "        for batch_idx, (data, targets) in enumerate(test_loader):\n",
    "            # Respect batch limit if specified\n",
    "            if batch_limit is not None and batch_idx >= batch_limit:\n",
    "                print(f\"Evaluating model on {batch_limit} batches (limited)...\")\n",
    "                break\n",
    "                \n",
    "            if batch_idx == 0:\n",
    "                print(f\"Evaluating model on {len(test_loader)} batches (all)...\")\n",
    "                \n",
    "            # Move data to device\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            # Use mixed precision if available\n",
    "            if mixed_precision_available:\n",
    "                with autocast_context():\n",
    "                    outputs = model(data)\n",
    "                    loss = criterion(outputs, targets)\n",
    "            else:\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "            # Accumulate loss\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Get predictions\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            # Update metrics\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            # Store probabilities for ROC curve (using softmax)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "            # Update confusion matrix\n",
    "            for t, p in zip(targets.view(-1), predicted.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "                \n",
    "            # Update per-class metrics\n",
    "            for i in range(len(targets)):\n",
    "                label = targets[i].item()\n",
    "                pred = predicted[i].item()\n",
    "                class_total[label] += 1\n",
    "                if label == pred:\n",
    "                    class_correct[label] += 1\n",
    "                    \n",
    "            # Update precision, recall metrics\n",
    "            for c in range(num_classes):\n",
    "                true_positives[c] += ((predicted == c) & (targets == c)).sum().item()\n",
    "                false_positives[c] += ((predicted == c) & (targets != c)).sum().item()\n",
    "                false_negatives[c] += ((predicted != c) & (targets == c)).sum().item()\n",
    "                \n",
    "            # Collect sample images for visualization\n",
    "            if samples_collected < max_samples:\n",
    "                # Get a few samples from this batch\n",
    "                num_to_collect = min(max_samples - samples_collected, data.size(0))\n",
    "                sample_images.extend(data[:num_to_collect].cpu())\n",
    "                sample_labels.extend(targets[:num_to_collect].cpu().numpy())\n",
    "                sample_preds.extend(predicted[:num_to_collect].cpu().numpy())\n",
    "                samples_collected += num_to_collect\n",
    "                \n",
    "            # Clean up memory\n",
    "            del data, targets, outputs, predicted\n",
    "            \n",
    "    # Compute average loss\n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    # Compute per-class accuracy\n",
    "    class_accuracy = [100. * class_correct[i] / max(1, class_total[i]) for i in range(num_classes)]\n",
    "    \n",
    "    # Compute precision, recall, F1\n",
    "    precision = [true_positives[i] / max(1, true_positives[i] + false_positives[i]) for i in range(num_classes)]\n",
    "    recall = [true_positives[i] / max(1, true_positives[i] + false_negatives[i]) for i in range(num_classes)]\n",
    "    f1_score = [2 * precision[i] * recall[i] / max(1e-6, precision[i] + recall[i]) for i in range(num_classes)]\n",
    "    \n",
    "    # Calculate macro averages\n",
    "    macro_precision = sum(precision) / num_classes\n",
    "    macro_recall = sum(recall) / num_classes\n",
    "    macro_f1 = sum(f1_score) / num_classes\n",
    "    \n",
    "    # Convert confusion matrix to percentage\n",
    "    confusion_percentage = confusion_matrix.diag() / confusion_matrix.sum(1)\n",
    "    \n",
    "    # Track total processing time\n",
    "    eval_time = time.time() - start_time\n",
    "    \n",
    "    # Return a comprehensive metrics dictionary\n",
    "    metrics = {\n",
    "        'loss': test_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'class_accuracy': dict(zip(class_names, class_accuracy)),\n",
    "        'precision': dict(zip(class_names, precision)),\n",
    "        'recall': dict(zip(class_names, recall)),\n",
    "        'f1_score': dict(zip(class_names, f1_score)),\n",
    "        'macro_precision': macro_precision,\n",
    "        'macro_recall': macro_recall,\n",
    "        'macro_f1': macro_f1,\n",
    "        'confusion_matrix': confusion_matrix.cpu().numpy(),\n",
    "        'confusion_percentage': confusion_percentage.cpu().numpy(),\n",
    "        'class_distribution': dict(zip(class_names, class_total)),\n",
    "        'evaluation_time': eval_time,\n",
    "        'samples': {\n",
    "            'images': sample_images,\n",
    "            'true_labels': sample_labels,\n",
    "            'predicted_labels': sample_preds,\n",
    "        },\n",
    "        'roc_data': {\n",
    "            'targets': all_targets,\n",
    "            'probs': all_probs,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ccec55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory-Efficient Training Function with Version-Compatible Autocast\n",
    "def train_memory_efficient(model, train_loader, criterion, optimizer, num_epochs, device,\n",
    "                          scheduler=None, gradient_accumulation_steps=1, memory_efficient=True,\n",
    "                          gc_frequency=10, use_mixed_precision=False, \n",
    "                          early_stopping_patience=None):\n",
    "    \"\"\"\n",
    "    Memory-efficient training function for BNN model\n",
    "    \n",
    "    Args:\n",
    "        model: The BNN model\n",
    "        train_loader: DataLoader for the training dataset\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer for training\n",
    "        num_epochs: Number of training epochs\n",
    "        device: Device to train on (cpu or cuda)\n",
    "        scheduler: Learning rate scheduler (optional)\n",
    "        gradient_accumulation_steps: Number of steps to accumulate gradients\n",
    "        memory_efficient: Whether to use memory efficiency techniques\n",
    "        gc_frequency: How often to perform garbage collection\n",
    "        use_mixed_precision: Whether to use mixed precision training\n",
    "        early_stopping_patience: Patience for early stopping (optional)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with training metrics\n",
    "    \"\"\"\n",
    "    # Import torch at the beginning of the function to avoid UnboundLocalError\n",
    "    import torch\n",
    "    import time\n",
    "    import gc\n",
    "    import contextlib\n",
    "    \n",
    "    # Training history\n",
    "    history = []\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    \n",
    "    # For early stopping\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # For timing\n",
    "    epoch_times = []\n",
    "    \n",
    "    # Mixed precision setup\n",
    "    mixed_precision_available = use_mixed_precision and hasattr(torch, 'autocast')\n",
    "    \n",
    "    # Setup mixed precision tools if available\n",
    "    if mixed_precision_available:\n",
    "        try:\n",
    "            from torch.cuda.amp import autocast, GradScaler\n",
    "            scaler = GradScaler()\n",
    "        except ImportError:\n",
    "            try:\n",
    "                from torch.amp import autocast, GradScaler\n",
    "                scaler = GradScaler()\n",
    "            except ImportError:\n",
    "                mixed_precision_available = False\n",
    "                scaler = None\n",
    "    else:\n",
    "        scaler = None\n",
    "\n",
    "    # Determine the appropriate autocast context manager based on PyTorch version\n",
    "    if mixed_precision_available:\n",
    "        try:\n",
    "            from torch.cuda.amp import autocast\n",
    "            # Check if the version supports device_type parameter\n",
    "            torch_version = torch.__version__\n",
    "            supports_device_type = int(torch_version.split('.')[0]) >= 1 and int(torch_version.split('.')[1]) >= 10\n",
    "            \n",
    "            # Define context manager with appropriate parameters\n",
    "            if supports_device_type:\n",
    "                autocast_context = lambda: autocast(device_type=device.type)\n",
    "            else:\n",
    "                # Older PyTorch versions only support CUDA and don't need device_type\n",
    "                autocast_context = lambda: autocast()\n",
    "        except ImportError:\n",
    "            try:\n",
    "                from torch.amp import autocast\n",
    "                autocast_context = lambda: autocast(device_type=device.type)\n",
    "            except ImportError:\n",
    "                mixed_precision_available = False\n",
    "                autocast_context = contextlib.nullcontext\n",
    "    else:\n",
    "        autocast_context = contextlib.nullcontext\n",
    "    \n",
    "    # Main training loop\n",
    "    print(f\"Starting training for {num_epochs} epochs with mixed precision: {mixed_precision_available}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        # Reset gradients at the start of each epoch for consistent behavior\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Process batches\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            # Move data to device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass with mixed precision if available\n",
    "            if mixed_precision_available:\n",
    "                with autocast_context():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # Adjust loss for gradient accumulation\n",
    "                    loss = loss / gradient_accumulation_steps\n",
    "                \n",
    "                # Backward pass with gradient scaling\n",
    "                scaler.scale(loss).backward()\n",
    "                \n",
    "                # Step with gradient accumulation\n",
    "                if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "            else:\n",
    "                # Standard forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Adjust loss for gradient accumulation\n",
    "                loss = loss / gradient_accumulation_steps\n",
    "                \n",
    "                # Standard backward pass\n",
    "                loss.backward()\n",
    "                \n",
    "                # Step with gradient accumulation\n",
    "                if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * gradient_accumulation_steps  # Rescale loss for reporting\n",
    "            running_corrects += torch.sum(preds == labels.data).item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            # Memory cleanup\n",
    "            if memory_efficient and (batch_idx + 1) % gc_frequency == 0:\n",
    "                del inputs, labels, outputs, preds, loss\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                \n",
    "        # Make sure to step optimizer for the last batch if not divisible\n",
    "        if mixed_precision_available and train_loader.__len__() % gradient_accumulation_steps != 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        elif not mixed_precision_available and train_loader.__len__() % gradient_accumulation_steps != 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        # Calculate epoch metrics\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = running_corrects / total_samples * 100.0\n",
    "        \n",
    "        # Step scheduler if provided\n",
    "        if scheduler is not None:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(epoch_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "            \n",
    "        # Record metrics\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "        \n",
    "        # Record epoch time\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_time = epoch_end_time - epoch_start_time\n",
    "        epoch_times.append(epoch_time)\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.2f}%, Time: {epoch_time:.2f}s')\n",
    "        \n",
    "        # Save epoch history\n",
    "        history.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'loss': epoch_loss,\n",
    "            'accuracy': epoch_acc,\n",
    "            'time': epoch_time,\n",
    "            'learning_rate': optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "        \n",
    "        # Memory cleanup at the end of epoch\n",
    "        if memory_efficient:\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "        # Early stopping check\n",
    "        if early_stopping_patience is not None:\n",
    "            if epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                \n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f'Early stopping at epoch {epoch+1}')\n",
    "                break\n",
    "                \n",
    "    # Return training metrics\n",
    "    training_summary = {\n",
    "        'history': history,\n",
    "        'train_losses': train_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'epoch_times': epoch_times,\n",
    "        'total_time': sum(epoch_times),\n",
    "        'final_loss': train_losses[-1],\n",
    "        'final_accuracy': train_accuracies[-1]\n",
    "    }\n",
    "    \n",
    "    return training_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "880c4285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial memory status:\n",
      "System memory: 15.0 GB total, 9.0 GB available, 39.6% used\n",
      "GPU: NVIDIA GeForce GTX 1650\n",
      "Memory allocated: 0.00 GB\n",
      "Memory reserved: 0.00 GB\n",
      "Max memory allocated: 0.00 GB\n",
      "\n",
      "Memory Summary:\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "\n",
      "Using aggressive memory optimization settings\n",
      "Recommended settings: {'image_size': 224, 'batch_size': 4, 'hidden_size': 256, 'embedding_size': 512, 'num_hidden_layers': 1, 'gradient_accumulation': 8, 'max_samples_per_class': 100}\n",
      "\n",
      "Results directory created: ./results/\n"
     ]
    }
   ],
   "source": [
    "# Memory Monitoring and Optimization Utilities\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "def print_gpu_memory_stats():\n",
    "    \"\"\"Print detailed GPU memory statistics\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        allocated = torch.cuda.memory_allocated() / (1024 ** 3)\n",
    "        reserved = torch.cuda.memory_reserved() / (1024 ** 3)\n",
    "        max_allocated = torch.cuda.max_memory_allocated() / (1024 ** 3)\n",
    "        \n",
    "        print(f\"Memory allocated: {allocated:.2f} GB\")\n",
    "        print(f\"Memory reserved: {reserved:.2f} GB\")\n",
    "        print(f\"Max memory allocated: {max_allocated:.2f} GB\")\n",
    "        \n",
    "        if hasattr(torch.cuda, 'memory_summary'):\n",
    "            print(\"\\nMemory Summary:\")\n",
    "            print(torch.cuda.memory_summary(abbreviated=True))\n",
    "    else:\n",
    "        print(\"CUDA not available\")\n",
    "\n",
    "def print_system_memory():\n",
    "    \"\"\"Print system memory usage\"\"\"\n",
    "    vm = psutil.virtual_memory()\n",
    "    print(f\"System memory: {vm.total / (1024**3):.1f} GB total, \" \n",
    "          f\"{vm.available / (1024**3):.1f} GB available, \"\n",
    "          f\"{vm.percent}% used\")\n",
    "\n",
    "def optimize_memory(mode='aggressive'):\n",
    "    \"\"\"Apply memory optimization settings based on selected mode\"\"\"\n",
    "    if mode == 'aggressive':\n",
    "        # Most aggressive memory saving settings for 224x224 images\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True,max_split_size_mb:32'\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        return {\n",
    "            'image_size': 224,  # 224x224 for this notebook\n",
    "            'batch_size': 4,  # Smaller batch size for larger images\n",
    "            'hidden_size': 256,\n",
    "            'embedding_size': 512,\n",
    "            'num_hidden_layers': 1,\n",
    "            'gradient_accumulation': 8,\n",
    "            'max_samples_per_class': 100  # Limit samples for 224x224 images\n",
    "        }\n",
    "    elif mode == 'moderate':\n",
    "        # Balanced memory saving\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True,max_split_size_mb:64'\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        return {\n",
    "            'image_size': 224,  # 224x224 for this notebook\n",
    "            'batch_size': 6,\n",
    "            'hidden_size': 320,\n",
    "            'embedding_size': 640,\n",
    "            'num_hidden_layers': 1,\n",
    "            'gradient_accumulation': 4,\n",
    "            'max_samples_per_class': 150\n",
    "        }\n",
    "    else:  # 'performance' mode\n",
    "        # Optimized for performance, higher memory usage\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        return {\n",
    "            'image_size': 224,  # 224x224 for this notebook\n",
    "            'batch_size': 8,\n",
    "            'hidden_size': 512,\n",
    "            'embedding_size': 1024,\n",
    "            'num_hidden_layers': 2,\n",
    "            'gradient_accumulation': 2,\n",
    "            'max_samples_per_class': None\n",
    "        }\n",
    "\n",
    "# Check current memory status\n",
    "print(\"Initial memory status:\")\n",
    "print_system_memory()\n",
    "print_gpu_memory_stats()\n",
    "\n",
    "# Memory optimization mode - set this to 'performance', 'moderate', or 'aggressive'\n",
    "memory_mode = 'aggressive'  # Using aggressive mode to avoid CUDA OOM errors\n",
    "print(f\"\\nUsing {memory_mode} memory optimization settings\")\n",
    "memory_config = optimize_memory(memory_mode)\n",
    "print(f\"Recommended settings: {memory_config}\")\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs('results', exist_ok=True)\n",
    "print(\"\\nResults directory created: ./results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c75b5f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path set to: /home/dragoon/Downloads/MH-SoyaHealthVision An Indian UAV and Leaf Image Dataset for Integrated Crop Health Assessment/dataset\n",
      "Make sure this path contains your plant disease class folders\n",
      "✅ Path exists!\n",
      "Found 4 class folders: ['Soyabean Semilooper_Pest_Attack', 'rust', 'Healthy_Soyabean', 'Soyabean_Mosaic']\n"
     ]
    }
   ],
   "source": [
    "# Set Dataset Path\n",
    "# This is the path to your plant disease dataset\n",
    "# You need to modify this path to point to your actual dataset location\n",
    "# The dataset should have a folder structure like:\n",
    "# - dataset_path/Healthy_Soyabean/\n",
    "# - dataset_path/rust/\n",
    "# - dataset_path/Soyabean_Mosaic/\n",
    "# or similar class folders\n",
    "\n",
    "# dataset_path = \"/home/dragoon/Downloads/MH-SoyaHealthVision An Indian UAV and Leaf Image Dataset for Integrated Crop Health Assessment/Soyabean_UAV-Based_Image_Dataset\" # MODIFY THIS PATH to your dataset location\n",
    "dataset_path = \"/home/dragoon/Downloads/MH-SoyaHealthVision An Indian UAV and Leaf Image Dataset for Integrated Crop Health Assessment/dataset\" # MODIFY THIS PATH to your dataset location\n",
    "\n",
    "print(f\"Dataset path set to: {dataset_path}\")\n",
    "print(\"Make sure this path contains your plant disease class folders\")\n",
    "\n",
    "# Check if the path exists\n",
    "import os\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"✅ Path exists!\")\n",
    "    # List the folders (classes) in the dataset\n",
    "    class_folders = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]\n",
    "    print(f\"Found {len(class_folders)} class folders: {class_folders}\")\n",
    "else:\n",
    "    print(\"❌ Path does not exist! Please update the dataset_path variable to your actual dataset location.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ed0da85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size set to 224x224 (from memory config)\n",
      "Loading plant disease dataset...\n",
      "Dataset path: /home/dragoon/Downloads/MH-SoyaHealthVision An Indian UAV and Leaf Image Dataset for Integrated Crop Health Assessment/dataset\n",
      "Dataset limited to 100 samples per class (169 total samples)\n",
      "Class mapping:\n",
      "  0: Healthy_Soyabean\n",
      "  1: Soyabean Semilooper_Pest_Attack\n",
      "  2: Soyabean_Mosaic\n",
      "  3: rust\n",
      "\n",
      "Class distribution:\n",
      "  Healthy_Soyabean: 49 images\n",
      "  Soyabean Semilooper_Pest_Attack: 40 images\n",
      "  Soyabean_Mosaic: 40 images\n",
      "  rust: 40 images\n",
      "\n",
      "Dataset loaded successfully in memory-efficient mode!\n",
      "Total samples: 169\n",
      "Number of classes: 4\n",
      "Class names: ['Healthy_Soyabean', 'Soyabean Semilooper_Pest_Attack', 'Soyabean_Mosaic', 'rust']\n"
     ]
    }
   ],
   "source": [
    "# Load Plant Disease Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def load_plant_disease_dataset(dataset_path, image_size=224, memory_efficient=True, max_samples_per_class=None):\n",
    "    \"\"\"\n",
    "    Load the plant disease dataset from the specified path with memory optimization options.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset_path : str\n",
    "        Path to dataset directory\n",
    "    image_size : int\n",
    "        Size to resize images (default: 224)\n",
    "    memory_efficient : bool\n",
    "        If True, loads dataset with memory optimization (returns DataLoader instead of tensors)\n",
    "    max_samples_per_class : int or None\n",
    "        If specified, limits the number of samples per class (for testing with less memory)\n",
    "    \n",
    "    Dataset structure:\n",
    "    - dataset_path/Healthy_Soyabean/\n",
    "    - dataset_path/rust/\n",
    "    - dataset_path/Soyabean_Mosaic/\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define transforms for preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),  # Resize to specified size\n",
    "        transforms.ToTensor(),  # Convert to tensor and normalize to [0,1]\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "    ])\n",
    "    \n",
    "    # Load dataset using ImageFolder\n",
    "    dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "    \n",
    "    # Limit samples per class if specified (for memory-constrained environments)\n",
    "    if max_samples_per_class is not None:\n",
    "        class_indices = {}\n",
    "        for idx, (_, class_idx) in enumerate(dataset.samples):\n",
    "            if class_idx not in class_indices:\n",
    "                class_indices[class_idx] = []\n",
    "            if len(class_indices[class_idx]) < max_samples_per_class:\n",
    "                class_indices[class_idx].append(idx)\n",
    "        \n",
    "        # Flatten indices list\n",
    "        limited_indices = [idx for indices in class_indices.values() for idx in indices]\n",
    "        \n",
    "        # Create subset\n",
    "        from torch.utils.data import Subset\n",
    "        dataset = Subset(dataset, limited_indices)\n",
    "        print(f\"Dataset limited to {max_samples_per_class} samples per class ({len(limited_indices)} total samples)\")\n",
    "    \n",
    "    # Print class mapping\n",
    "    print(\"Class mapping:\")\n",
    "    for idx, class_name in enumerate(dataset.dataset.classes if hasattr(dataset, 'dataset') else dataset.classes):\n",
    "        print(f\"  {idx}: {class_name}\")\n",
    "    \n",
    "    # Return dataset directly for memory-efficient use\n",
    "    if memory_efficient:\n",
    "        # Count samples per class for data statistics\n",
    "        class_counts = {}\n",
    "        if hasattr(dataset, 'dataset'):  # If it's a Subset\n",
    "            for _, class_idx in [dataset.dataset.samples[i] for i in dataset.indices]:\n",
    "                class_counts[class_idx] = class_counts.get(class_idx, 0) + 1\n",
    "            classes = dataset.dataset.classes\n",
    "        else:\n",
    "            for _, class_idx in dataset.samples:\n",
    "                class_counts[class_idx] = class_counts.get(class_idx, 0) + 1\n",
    "            classes = dataset.classes\n",
    "        \n",
    "        # Display class distribution\n",
    "        print(f\"\\nClass distribution:\")\n",
    "        for class_idx, count in class_counts.items():\n",
    "            class_name = classes[class_idx]\n",
    "            print(f\"  {class_name}: {count} images\")\n",
    "        \n",
    "        return dataset, classes\n",
    "    else:\n",
    "        # Convert to tensors (this loads ALL images into memory)\n",
    "        data_loader = torch.utils.data.DataLoader(dataset, batch_size=len(dataset), shuffle=False)\n",
    "        X, y = next(iter(data_loader))\n",
    "        \n",
    "        # Get class names from dataset\n",
    "        if hasattr(dataset, 'dataset'):\n",
    "            class_names = dataset.dataset.classes\n",
    "        else:\n",
    "            class_names = dataset.classes\n",
    "        \n",
    "        return X, y, class_names\n",
    "\n",
    "# Set memory optimization options from memory config\n",
    "memory_efficient = True  # Load dataset in memory-efficient way\n",
    "max_samples_per_class = memory_config['max_samples_per_class']  # From memory config\n",
    "\n",
    "# Image size settings from memory config\n",
    "image_size = memory_config.get('image_size', 224)\n",
    "print(f\"Image size set to {image_size}x{image_size} (from memory config)\")\n",
    "\n",
    "# Load your plant disease dataset\n",
    "# Using the dataset_path defined in the previous cell\n",
    "print(\"Loading plant disease dataset...\")\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "\n",
    "if memory_efficient:\n",
    "    # Memory-efficient loading (doesn't load all images at once)\n",
    "    plant_dataset, class_names = load_plant_disease_dataset(\n",
    "        dataset_path, \n",
    "        image_size=image_size, \n",
    "        memory_efficient=memory_efficient,\n",
    "        max_samples_per_class=max_samples_per_class\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDataset loaded successfully in memory-efficient mode!\")\n",
    "    print(f\"Total samples: {len(plant_dataset)}\")\n",
    "    print(f\"Number of classes: {len(class_names)}\")\n",
    "    print(f\"Class names: {class_names}\")\n",
    "else:\n",
    "    # Original approach (loads all into memory at once)\n",
    "    X, y, class_names = load_plant_disease_dataset(\n",
    "        dataset_path, \n",
    "        image_size=image_size, \n",
    "        memory_efficient=False,\n",
    "        max_samples_per_class=max_samples_per_class\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDataset loaded successfully!\")\n",
    "    print(f\"Dataset shape: {X.shape}\")\n",
    "    print(f\"Labels shape: {y.shape}\")\n",
    "    print(f\"Number of classes: {len(torch.unique(y))}\")\n",
    "    print(f\"Class distribution: {torch.bincount(y)}\")\n",
    "    print(f\"Class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b28af394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using batch size 4 for 224x224 images\n",
      "Training set: 136 samples\n",
      "Test set: 33 samples\n",
      "Number of training batches: 34\n",
      "Number of test batches: 9\n"
     ]
    }
   ],
   "source": [
    "# Split Dataset and Create Data Loaders\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "# Define batch size from memory_config for consistency\n",
    "batch_size = memory_config['batch_size']  # Use memory-optimized batch size\n",
    "print(f\"Using batch size {batch_size} for {image_size}x{image_size} images\")\n",
    "\n",
    "if memory_efficient:\n",
    "    # Create train/test split indices\n",
    "    from torch.utils.data import random_split\n",
    "    \n",
    "    # Use fixed random seed for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # Get dataset size\n",
    "    dataset_size = len(plant_dataset)\n",
    "    test_size = int(0.2 * dataset_size)\n",
    "    train_size = dataset_size - test_size\n",
    "    \n",
    "    # Create random train/test split\n",
    "    train_dataset, test_dataset = random_split(plant_dataset, [train_size, test_size])\n",
    "    \n",
    "    # Create data loaders with smaller batch size for memory efficiency\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=0,  # Increase if your system allows\n",
    "        pin_memory=False  # Use pinned memory for faster GPU transfer\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=0,  # Increase if your system allows\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    # Print info about data loaders\n",
    "    print(f\"Training set: {len(train_dataset)} samples\")\n",
    "    print(f\"Test set: {len(test_dataset)} samples\")\n",
    "    print(f\"Number of training batches: {len(train_loader)}\")\n",
    "    print(f\"Number of test batches: {len(test_loader)}\")\n",
    "    \n",
    "    # Store for later reference\n",
    "    dataset_size = {'train': len(train_dataset), 'test': len(test_dataset)}\n",
    "    \n",
    "else:\n",
    "    # Original approach with pre-loaded tensors\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "    print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "    # Create data loaders\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"Number of training batches: {len(train_loader)}\")\n",
    "    print(f\"Number of test batches: {len(test_loader)}\")\n",
    "    \n",
    "    # Store for later reference\n",
    "    dataset_size = {'train': len(X_train), 'test': len(X_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f18c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Activation Function\n",
    "class BinaryActivation(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Binary activation function using the sign function.\n",
    "    Forward: sign(x) = {-1 if x < 0, +1 if x >= 0}\n",
    "    Backward: Straight-through estimator (STE) - passes gradients through unchanged\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # Apply sign function: -1 for negative, +1 for non-negative\n",
    "        return torch.sign(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Straight-through estimator: pass gradients through unchanged\n",
    "        # This allows gradients to flow back during training\n",
    "        return grad_output\n",
    "\n",
    "def binary_activation(x):\n",
    "    \"\"\"Wrapper function for binary activation\"\"\"\n",
    "    return BinaryActivation.apply(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af5c5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Linear Layer\n",
    "class BinaryLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    Binary Linear layer with binary weights.\n",
    "    Weights are binarized using the sign function during forward pass.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(BinaryLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        # Initialize weights using normal distribution\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features) * 0.1)\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # Binarize weights using sign function\n",
    "        binary_weight = torch.sign(self.weight)\n",
    "        \n",
    "        # Perform linear transformation with binary weights\n",
    "        output = F.linear(input, binary_weight, self.bias)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        return f'in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5260f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Neural Network Model\n",
    "class BinaryNeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Memory-efficient Binary Neural Network for multiclass plant disease classification.\n",
    "    \n",
    "    Architecture:\n",
    "    - Input: Flattened RGB images (3*image_size*image_size features)\n",
    "    - Progressive dimensionality reduction: Multiple steps to reduce memory usage\n",
    "    - Feature embedding: Further reduces dimensionality for memory efficiency \n",
    "    - Binary Hidden Layers: Binary linear layers with binary activation\n",
    "    - Output Layer: Regular linear layer for class logits\n",
    "    - Final: Softmax for multiclass prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=3*224*224, hidden_size=256, num_classes=3, \n",
    "                 num_hidden_layers=1, embedding_size=512, dropout_rate=0.2):\n",
    "        super(BinaryNeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # Calculate intermediate sizes for progressive dimension reduction using more aggressive reduction\n",
    "        # This prevents OOM errors by using smaller intermediate layers\n",
    "        intermediate_size1 = min(input_size // 8, 16384)  # More aggressive first reduction\n",
    "        intermediate_size2 = min(intermediate_size1 // 4, 4096)  # Second reduction\n",
    "        intermediate_size3 = min(intermediate_size2 // 2, 2048)  # Additional reduction\n",
    "        intermediate_size4 = min(intermediate_size3 // 2, 1024)  # Final intermediate step before embedding\n",
    "        \n",
    "        print(f\"Progressive dimension reduction: {input_size} → {intermediate_size1} → {intermediate_size2} → {intermediate_size3} → {intermediate_size4} → {embedding_size}\")\n",
    "        \n",
    "        # Initial dimensionality reduction for memory efficiency - progressive steps with more stages\n",
    "        self.embedding = nn.Sequential(\n",
    "            # First reduction\n",
    "            nn.Linear(input_size, intermediate_size1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(intermediate_size1),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            # Second reduction\n",
    "            nn.Linear(intermediate_size1, intermediate_size2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(intermediate_size2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            # Third reduction\n",
    "            nn.Linear(intermediate_size2, intermediate_size3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(intermediate_size3),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            # Fourth reduction (added for more gradual reduction)\n",
    "            nn.Linear(intermediate_size3, intermediate_size4),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(intermediate_size4),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            # Final embedding\n",
    "            nn.Linear(intermediate_size4, embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(embedding_size),\n",
    "        )\n",
    "        \n",
    "        # First binary layer after embedding\n",
    "        self.input_binary = BinaryLinear(embedding_size, hidden_size)\n",
    "        \n",
    "        # Multiple hidden binary layers\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            BinaryLinear(hidden_size, hidden_size) for _ in range(num_hidden_layers)\n",
    "        ])\n",
    "        \n",
    "        # Output layer: Regular linear layer for final classification\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        # Batch normalization for better training stability\n",
    "        self.batch_norms = nn.ModuleList([\n",
    "            nn.BatchNorm1d(hidden_size) for _ in range(num_hidden_layers + 1)  # +1 for input binary layer\n",
    "        ])\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten input if it's not already flattened\n",
    "        if len(x.shape) > 2:\n",
    "            x = x.view(x.size(0), -1)  # Flatten to (batch_size, input_size)\n",
    "        \n",
    "        # Initial embedding to reduce dimensionality (memory efficient)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # First binary layer\n",
    "        x = self.input_binary(x)\n",
    "        x = binary_activation(x)\n",
    "        x = self.batch_norms[0](x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Process through additional hidden binary layers\n",
    "        for i in range(self.num_hidden_layers):\n",
    "            x = self.hidden_layers[i](x)\n",
    "            x = binary_activation(x)  # Binary activation function\n",
    "            x = self.batch_norms[i+1](x)  # Apply batch normalization\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        # Output layer (no activation - raw logits)\n",
    "        logits = self.output_layer(x)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        \"\"\"Get class probabilities using softmax\"\"\"\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            probabilities = F.softmax(logits, dim=1)\n",
    "        return probabilities\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"Get predicted class labels\"\"\"\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2365cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory-Optimized Binary Neural Network Model with Checkpointing\n",
    "class BinaryNeuralNetworkCheckpointed(nn.Module):\n",
    "    \"\"\"\n",
    "    Ultra memory-efficient Binary Neural Network using checkpointing and simplified architecture.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=3*64*64, hidden_size=64, num_classes=3, dropout_rate=0.3):\n",
    "        super(BinaryNeuralNetworkCheckpointed, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Simplified embedding with fewer stages to reduce memory\n",
    "        embedding_size = hidden_size * 2\n",
    "        intermediate_size1 = min(input_size // 4, 2048) \n",
    "        \n",
    "        # Create separate embedding layers for checkpointing\n",
    "        self.embed1 = nn.Sequential(\n",
    "            nn.Linear(input_size, intermediate_size1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(intermediate_size1),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.embed2 = nn.Sequential(\n",
    "            nn.Linear(intermediate_size1, embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(embedding_size)\n",
    "        )\n",
    "        \n",
    "        # Binary layers\n",
    "        self.binary_layer = BinaryLinear(embedding_size, hidden_size)\n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        print(f\"Memory-optimized BNN created with input={input_size}, hidden={hidden_size}, embedding={embedding_size}\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten input\n",
    "        if len(x.shape) > 2:\n",
    "            x = x.view(x.size(0), -1)\n",
    "            \n",
    "        # Use checkpointing for memory efficiency if available\n",
    "        if 'use_checkpointing' in globals() and use_checkpointing:\n",
    "            from torch.utils.checkpoint import checkpoint\n",
    "            x = checkpoint(self.embed1, x)\n",
    "            x = checkpoint(self.embed2, x)\n",
    "        else:\n",
    "            x = self.embed1(x)\n",
    "            x = self.embed2(x)\n",
    "        \n",
    "        # Binary layer (no checkpointing needed, it's small)\n",
    "        x = self.binary_layer(x)\n",
    "        x = binary_activation(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = self.output_layer(x)\n",
    "        return logits\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            probabilities = F.softmax(logits, dim=1)\n",
    "        return probabilities\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfd312fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultra Memory-Efficient BNN Model for 224x224 Images\n",
    "class BNN224x224MemoryOptimized(nn.Module):\n",
    "    \"\"\"\n",
    "    Memory-optimized BNN specifically designed for 224x224 images\n",
    "    using advanced techniques to minimize memory usage.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=3*224*224, hidden_size=64, num_classes=3, dropout_rate=0.5):\n",
    "        super(BNN224x224MemoryOptimized, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Import torch utils for checkpointing\n",
    "        from torch.utils.checkpoint import checkpoint_sequential\n",
    "        \n",
    "        # STRATEGY 1: Use Convolutional layers instead of fully connected for dimensionality reduction\n",
    "        # This drastically reduces parameters vs. flattening to 150528 (3*224*224) dimensions\n",
    "        self.conv_reducer = nn.Sequential(\n",
    "            # Conv block 1 - reduce to 112x112\n",
    "            nn.Conv2d(3, 8, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(2),  # 224 -> 112\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "            \n",
    "            # Conv block 2 - reduce to 56x56\n",
    "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(2),  # 112 -> 56\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            \n",
    "            # Conv block 3 - reduce to 28x28\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(2),  # 56 -> 28\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            # Conv block 4 - reduce to 14x14\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(2),  # 28 -> 14\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            \n",
    "            # Conv block 5 - reduce to 7x7\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(2),  # 14 -> 7\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            \n",
    "            # Final feature reduction\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),  # Global average pooling: 7x7 -> 1x1\n",
    "        )\n",
    "        \n",
    "        # STRATEGY 2: Keep the binary network very small\n",
    "        # After conv reduction, we have 64 features (from 64 channels * 1x1)\n",
    "        self.binary_layer = BinaryLinear(64, hidden_size)\n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Output classifier\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        # Print memory-optimized architecture details\n",
    "        conv_params = sum(p.numel() for p in self.conv_reducer.parameters())\n",
    "        binary_params = sum(p.numel() for p in self.binary_layer.parameters())\n",
    "        output_params = sum(p.numel() for p in self.output_layer.parameters())\n",
    "        total_params = conv_params + binary_params + output_params\n",
    "        \n",
    "        print(f\"Memory-optimized 224x224 BNN created:\")\n",
    "        print(f\"- Total parameters: {total_params:,} (vs. {3*224*224*hidden_size:,} for naive approach)\")\n",
    "        print(f\"- Parameter reduction: {100 - (total_params / (3*224*224*hidden_size)) * 100:.2f}%\")\n",
    "        print(f\"- Using gradient checkpointing: {USE_GRADIENT_CHECKPOINTING if 'USE_GRADIENT_CHECKPOINTING' in globals() else False}\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # If input is already flattened, reshape it to image format\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.view(-1, 3, 224, 224)\n",
    "            \n",
    "        # Process through convolutional feature extractor\n",
    "        # Use checkpointing if enabled to save memory during training\n",
    "        if 'USE_GRADIENT_CHECKPOINTING' in globals() and USE_GRADIENT_CHECKPOINTING and self.training:\n",
    "            from torch.utils.checkpoint import checkpoint\n",
    "            # Split the conv_reducer into chunks for checkpointing\n",
    "            modules = list(self.conv_reducer.children())\n",
    "            # Process in chunks of 4 modules\n",
    "            for i in range(0, len(modules), 4):\n",
    "                chunk = nn.Sequential(*modules[i:i+4])\n",
    "                x = checkpoint(lambda inp: chunk(inp), x)\n",
    "        else:\n",
    "            x = self.conv_reducer(x)\n",
    "        \n",
    "        # Flatten after convolutions\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Binary layer processing\n",
    "        x = self.binary_layer(x)\n",
    "        x = binary_activation(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Output layer\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f078dfa9",
   "metadata": {},
   "source": [
    "# Complete Memory Optimization Guide\n",
    "\n",
    "If you're still facing memory issues even with reduced batch size and 40 images per class, try these steps in order:\n",
    "\n",
    "## Step 1: Force CPU Mode\n",
    "If your GPU simply doesn't have enough memory, you can run the entire model on CPU:\n",
    "```python\n",
    "device = torch.device(\"cpu\")\n",
    "```\n",
    "\n",
    "## Step 2: Use Ultra-Small Images\n",
    "Reduce image size to 64x64 or even 32x32 pixels:\n",
    "```python\n",
    "memory_config['image_size'] = 32\n",
    "```\n",
    "\n",
    "## Step 3: Use the Checkpointed Model\n",
    "Use the memory-optimized model with checkpointing:\n",
    "```python\n",
    "# Use the checkpointed model instead of the original\n",
    "model = BinaryNeuralNetworkCheckpointed(\n",
    "    input_size=3 * image_size * image_size,\n",
    "    hidden_size=memory_config['hidden_size'],\n",
    "    num_classes=len(class_names),\n",
    "    dropout_rate=0.3\n",
    ")\n",
    "```\n",
    "\n",
    "## Step 4: Drastically Limit Dataset Size\n",
    "Reduce to even fewer images per class:\n",
    "```python\n",
    "memory_config['max_samples_per_class'] = 10  # Use only 10 images per class\n",
    "```\n",
    "\n",
    "## Step 5: Disable Mixed Precision\n",
    "Mixed precision can sometimes cause issues:\n",
    "```python\n",
    "memory_config['use_mixed_precision'] = False\n",
    "```\n",
    "\n",
    "## Step 6: Advanced Options\n",
    "For extreme cases:\n",
    "1. Disable gradient computation for most layers\n",
    "2. Use 16-bit floats (half precision) throughout\n",
    "3. Try training only the final layer and freezing the rest\n",
    "\n",
    "## Step 7: External Processing\n",
    "If all else fails:\n",
    "1. Pre-process and extract features on CPU\n",
    "2. Save features to disk\n",
    "3. Load and train only on the extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30b1c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory-Efficient Feature Preprocessing for 224x224 Images\n",
    "# This cell provides functions to preprocess images and extract features before training\n",
    "\n",
    "def create_feature_extractor_for_224():\n",
    "    \"\"\"Create a lightweight feature extractor for 224x224 images\"\"\"\n",
    "    import torchvision.models as models\n",
    "    from torch.utils.checkpoint import checkpoint_sequential\n",
    "    \n",
    "    # Use a pretrained model with the head removed\n",
    "    # MobileNet is much more memory efficient than other models\n",
    "    model = models.mobilenet_v2(pretrained=True)\n",
    "    \n",
    "    # Remove the classifier to get features only\n",
    "    feature_extractor = torch.nn.Sequential(*(list(model.features)))\n",
    "    \n",
    "    # Freeze the feature extractor to save memory during training\n",
    "    for param in feature_extractor.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    # Move to appropriate device\n",
    "    feature_extractor = feature_extractor.to(device)\n",
    "    feature_extractor.eval()\n",
    "    \n",
    "    return feature_extractor\n",
    "\n",
    "def extract_features_from_dataset(dataset, feature_extractor, batch_size=4):\n",
    "    \"\"\"Extract features from a dataset using a pre-trained model to reduce training memory\"\"\"\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    import time\n",
    "    \n",
    "    # Create a dataloader for the dataset\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Process in batches\n",
    "    print(f\"Extracting features from {len(dataset)} images...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(loader):\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Processing batch {batch_idx+1}/{len(loader)}...\")\n",
    "            \n",
    "            # Move to device\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Extract features\n",
    "            features = feature_extractor(images)\n",
    "            \n",
    "            # Global average pooling to get a fixed-size feature vector\n",
    "            features = torch.nn.functional.adaptive_avg_pool2d(features, (1, 1))\n",
    "            features = features.view(features.size(0), -1)\n",
    "            \n",
    "            # Store features and labels\n",
    "            all_features.append(features.cpu())\n",
    "            all_labels.append(labels)\n",
    "            \n",
    "            # Clean up to save memory\n",
    "            del images, features\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Concatenate all features and labels\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    \n",
    "    # Create a new TensorDataset with the extracted features\n",
    "    feature_dataset = TensorDataset(all_features, all_labels)\n",
    "    \n",
    "    print(f\"Feature extraction completed in {time.time() - start_time:.2f} seconds\")\n",
    "    print(f\"Extracted feature shape: {all_features.shape}\")\n",
    "    \n",
    "    return feature_dataset\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "# feature_extractor = create_feature_extractor_for_224()\n",
    "# train_feature_dataset = extract_features_from_dataset(train_dataset, feature_extractor)\n",
    "# test_feature_dataset = extract_features_from_dataset(test_dataset, feature_extractor)\n",
    "\n",
    "# Then create new data loaders with the feature datasets:\n",
    "# train_feature_loader = DataLoader(train_feature_dataset, batch_size=memory_config['batch_size'], shuffle=True)\n",
    "# test_feature_loader = DataLoader(test_feature_dataset, batch_size=memory_config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4e2589",
   "metadata": {},
   "source": [
    "# Complete Guide to Training with 224x224 Images\n",
    "\n",
    "This guide provides multiple strategies to train your model while maintaining 224x224 image size.\n",
    "\n",
    "## Strategy 1: Use Convolutional Architecture\n",
    "The `BNN224x224MemoryOptimized` class uses convolutional layers instead of flattening the entire image, which drastically reduces memory usage while maintaining the 224x224 input size.\n",
    "\n",
    "```python\n",
    "# Create the memory-optimized model for 224x224\n",
    "model = BNN224x224MemoryOptimized(\n",
    "    hidden_size=64,  # Smaller hidden size\n",
    "    num_classes=len(class_names),\n",
    "    dropout_rate=0.5  # Aggressive dropout\n",
    ").to(device)\n",
    "\n",
    "# Continue with training as normal using this model\n",
    "```\n",
    "\n",
    "## Strategy 2: Feature Pre-extraction\n",
    "Extract features once using a pre-trained model, then train on these features:\n",
    "\n",
    "```python\n",
    "# 1. Create feature extractor\n",
    "feature_extractor = create_feature_extractor_for_224()\n",
    "\n",
    "# 2. Process train and test datasets\n",
    "train_feature_dataset = extract_features_from_dataset(train_dataset, feature_extractor)\n",
    "test_feature_dataset = extract_features_from_dataset(test_dataset, feature_extractor)\n",
    "\n",
    "# 3. Create data loaders for the feature datasets\n",
    "train_feature_loader = DataLoader(train_feature_dataset, batch_size=32, shuffle=True)\n",
    "test_feature_loader = DataLoader(test_feature_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 4. Create a simple model that works with extracted features\n",
    "feature_model = nn.Sequential(\n",
    "    nn.Linear(1280, 256),  # MobileNetV2 features have 1280 dimensions\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256, len(class_names))\n",
    ").to(device)\n",
    "\n",
    "# 5. Train as normal using the feature_model and train_feature_loader\n",
    "```\n",
    "\n",
    "## Strategy 3: Train in CPU Mode\n",
    "If GPU memory is still an issue, force CPU mode:\n",
    "\n",
    "```python\n",
    "device = torch.device(\"cpu\")\n",
    "model = BNN224x224MemoryOptimized(...).to(device)\n",
    "```\n",
    "\n",
    "## Strategy 4: Advanced PyTorch Memory Optimization\n",
    "\n",
    "```python\n",
    "# 1. Use torch.compile for efficiency (PyTorch 2.0+)\n",
    "if hasattr(torch, 'compile'):\n",
    "    model = torch.compile(model)  # Uses dynamic shape tracing\n",
    "\n",
    "# 2. Disable gradient history for non-essential layers\n",
    "def set_requires_grad(model, requires_grad=False):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = requires_grad\n",
    "\n",
    "# Keep only the last layer trainable\n",
    "set_requires_grad(model, False)\n",
    "set_requires_grad(model.output_layer, True)\n",
    "\n",
    "# 3. Use 16-bit precision throughout\n",
    "model.half()  # Convert model to half precision\n",
    "```\n",
    "\n",
    "## Strategy 5: Activate NVIDIA Memory-Efficient Features\n",
    "For NVIDIA GPUs, set these environment variables:\n",
    "```python\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # Use only the first GPU\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb=32,garbage_collection_threshold=0.8'\n",
    "torch.backends.cudnn.benchmark = False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66909a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Ultra Memory-Efficient Configuration Example\n",
    "# Run this cell if you're still experiencing memory issues\n",
    "\n",
    "# 1. Force CPU mode if needed (uncomment to use)\n",
    "# device = torch.device(\"cpu\")\n",
    "# print(f\"Forced CPU mode: {device}\")\n",
    "\n",
    "# 2. Apply ultra-efficient memory config\n",
    "ultra_config = {\n",
    "    'batch_size': 1,\n",
    "    'gradient_accumulation_steps': 16,  # More gradient accumulation steps\n",
    "    'gc_frequency': 1,\n",
    "    'memory_efficient': True,\n",
    "    'use_mixed_precision': False,  # Disable mixed precision if on CPU\n",
    "    'image_size': 64,  # Drastically reduced image size\n",
    "    'hidden_size': 64,\n",
    "    'embedding_size': 128,\n",
    "    'max_samples_per_class': 10,  # Ultra-limited for testing\n",
    "    'num_workers': 0,\n",
    "    'pin_memory': False,\n",
    "}\n",
    "\n",
    "# Uncomment to apply this config\n",
    "# memory_config.update(ultra_config)\n",
    "# print(\"Ultra-efficient memory config applied!\")\n",
    "\n",
    "# 3. Create checkpointed model example\n",
    "def create_ultralight_model():\n",
    "    \"\"\"Create an ultra-memory efficient model\"\"\"\n",
    "    input_size = 3 * memory_config.get('image_size', 64) * memory_config.get('image_size', 64)\n",
    "    model = BinaryNeuralNetworkCheckpointed(\n",
    "        input_size=input_size,\n",
    "        hidden_size=memory_config.get('hidden_size', 64),\n",
    "        num_classes=len(class_names) if 'class_names' in globals() else 3,\n",
    "        dropout_rate=0.5  # More dropout for regularization\n",
    "    )\n",
    "    return model.to(device)\n",
    "\n",
    "# Example of creating the model (uncomment to use)\n",
    "# model = create_ultralight_model()\n",
    "# print(f\"Ultra-light model created with {sum(p.numel() for p in model.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a88aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressive dimension reduction: 150528 → 16384 → 4096 → 2048 → 1024 → 512\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the BNN Model\n",
    "# Calculate the input size based on the image size\n",
    "input_size = 3 * image_size * image_size  # For RGB images (3 channels)\n",
    "hidden_size = memory_config['hidden_size']\n",
    "embedding_size = memory_config['embedding_size']\n",
    "num_hidden_layers = memory_config.get('num_hidden_layers', 1)\n",
    "\n",
    "# Get the number of classes from the dataset\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Create an instance of the BNN model\n",
    "model = BinaryNeuralNetwork(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_classes=num_classes,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    embedding_size=embedding_size,\n",
    "    dropout_rate=0.2\n",
    ")\n",
    "\n",
    "# Move model to device (GPU if available)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model architecture summary\n",
    "print(f\"Binary Neural Network Architecture:\")\n",
    "print(f\"- Input size: {input_size} (3 channels × {image_size} × {image_size})\")\n",
    "print(f\"- Hidden size: {hidden_size}\")\n",
    "print(f\"- Embedding size: {embedding_size}\")\n",
    "print(f\"- Hidden layers: {num_hidden_layers}\")\n",
    "print(f\"- Output classes: {num_classes} ({class_names})\")\n",
    "print(f\"- Device: {device}\")\n",
    "\n",
    "# Count the number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Print the full model architecture for reference\n",
    "print(\"\\nDetailed model architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5257b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Training Parameters\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Loss function - CrossEntropyLoss for multi-class classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer - Adam with a relatively low learning rate for stability\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Learning rate scheduler - reduce on plateau\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min',  # Minimize loss\n",
    "    factor=0.5,  # Reduce LR by half when triggered\n",
    "    patience=3,  # Wait 3 epochs for improvement\n",
    "    verbose=True,\n",
    "    min_lr=0.00001  # Don't go below this learning rate\n",
    ")\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 20  # SET THE NUMBER OF EPOCHS HERE\n",
    "early_stopping_patience = 5  # Stop training if no improvement for this many epochs\n",
    "\n",
    "# Gradient accumulation steps from memory config\n",
    "gradient_accumulation_steps = memory_config.get('gradient_accumulation_steps', 1)\n",
    "\n",
    "# Print training configuration\n",
    "print(f\"Training Configuration:\")\n",
    "print(f\"- Number of epochs: {num_epochs}\")\n",
    "print(f\"- Learning rate: {learning_rate}\")\n",
    "print(f\"- Loss function: CrossEntropyLoss\")\n",
    "print(f\"- Optimizer: Adam\")\n",
    "print(f\"- Scheduler: ReduceLROnPlateau (factor=0.5, patience=3)\")\n",
    "print(f\"- Early stopping patience: {early_stopping_patience}\")\n",
    "print(f\"- Gradient accumulation steps: {gradient_accumulation_steps}\")\n",
    "print(f\"- Effective batch size: {batch_size * gradient_accumulation_steps}\")\n",
    "print(f\"- Mixed precision: {use_mixed_precision}\")\n",
    "print(f\"- Memory efficient: {memory_efficient}\")\n",
    "print(f\"- GC frequency: {gc_frequency}\")\n",
    "print(f\"\\nTraining will begin with {num_epochs} epochs...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Record the start time for overall training\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "print(f\"Training on {len(train_dataset)} samples, validating on {len(test_dataset)} samples\")\n",
    "\n",
    "# Use the memory-efficient training function defined earlier\n",
    "training_results = train_memory_efficient(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device,\n",
    "    scheduler=scheduler,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    memory_efficient=memory_efficient,\n",
    "    gc_frequency=gc_frequency,\n",
    "    use_mixed_precision=use_mixed_precision,\n",
    "    early_stopping_patience=early_stopping_patience\n",
    ")\n",
    "\n",
    "# Calculate total training time\n",
    "total_time = time.time() - start_time\n",
    "hours, remainder = divmod(total_time, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "print(f\"\\nTraining completed in {int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\")\n",
    "print(f\"Final loss: {training_results['final_loss']:.4f}\")\n",
    "print(f\"Final accuracy: {training_results['final_accuracy']:.2f}%\")\n",
    "\n",
    "# Plot training metrics\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(training_results['train_losses'], 'b-', label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(training_results['train_accuracies'], 'g-', label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the training history to CSV\n",
    "import pandas as pd\n",
    "history_df = pd.DataFrame(training_results['history'])\n",
    "history_df.to_csv('results/bnn_224x224_training_history.csv', index=False)\n",
    "print(\"Training history saved to results/bnn_224x224_training_history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Trained Model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Evaluating model on test dataset...\")\n",
    "\n",
    "# Use the memory-efficient evaluation function\n",
    "eval_results = evaluate_bnn_memory_efficient(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    use_mixed_precision=use_mixed_precision\n",
    ")\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"\\nEvaluation Results:\")\n",
    "print(f\"Test Loss: {eval_results['loss']:.4f}\")\n",
    "print(f\"Test Accuracy: {eval_results['accuracy']:.2f}%\")\n",
    "print(f\"Macro Precision: {eval_results['macro_precision']:.4f}\")\n",
    "print(f\"Macro Recall: {eval_results['macro_recall']:.4f}\")\n",
    "print(f\"Macro F1 Score: {eval_results['macro_f1']:.4f}\")\n",
    "print(f\"\\nPer-Class Accuracy:\")\n",
    "for class_name, acc in eval_results['class_accuracy'].items():\n",
    "    print(f\"  {class_name}: {acc:.2f}%\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = eval_results['confusion_matrix']\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save evaluation results\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Convert numpy arrays to lists for JSON serialization\n",
    "serializable_results = {k: (v.tolist() if isinstance(v, np.ndarray) else v) \n",
    "                        for k, v in eval_results.items()\n",
    "                        if k not in ['samples', 'roc_data']}  # Exclude image data\n",
    "\n",
    "with open('results/bnn_224x224_evaluation_results.json', 'w') as f:\n",
    "    json.dump(serializable_results, f, indent=2)\n",
    "    \n",
    "print(\"Evaluation results saved to results/bnn_224x224_evaluation_results.json\")\n",
    "\n",
    "# Save the trained model\n",
    "model_save_path = 'results/bnn_224x224_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'class_names': class_names,\n",
    "    'config': {\n",
    "        'input_size': input_size,\n",
    "        'hidden_size': hidden_size,\n",
    "        'embedding_size': embedding_size,\n",
    "        'num_hidden_layers': num_hidden_layers,\n",
    "        'num_classes': num_classes,\n",
    "        'image_size': image_size\n",
    "    }\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"Trained model saved to {model_save_path}\")\n",
    "print(\"\\nTraining and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f13e44",
   "metadata": {},
   "source": [
    "# Advanced Memory Optimization Guide for 224x224 Images\n",
    "\n",
    "This guide provides the most extreme memory optimization techniques that maintain 224x224 image resolution for high-detail plant disease classification.\n",
    "\n",
    "## Technique 1: Patch-Based Processing\n",
    "\n",
    "Process images in smaller patches rather than whole images:\n",
    "\n",
    "```python\n",
    "def patch_based_inference(model, image, patch_size=112, stride=56):\n",
    "    \"\"\"Process a 224x224 image in smaller patches to reduce memory usage\"\"\"\n",
    "    # Implementation:\n",
    "    # 1. Split the image into overlapping patches\n",
    "    # 2. Process each patch separately\n",
    "    # 3. Combine the results (averaging overlapping areas)\n",
    "    # This allows processing high-res images with much less memory\n",
    "    patches = []\n",
    "    h, w = image.shape[2], image.shape[3]\n",
    "    \n",
    "    # Extract patches\n",
    "    for y in range(0, h-patch_size+1, stride):\n",
    "        for x in range(0, w-patch_size+1, stride):\n",
    "            patch = image[:, :, y:y+patch_size, x:x+patch_size]\n",
    "            patches.append(patch)\n",
    "    \n",
    "    # Process each patch\n",
    "    patch_features = []\n",
    "    for patch in patches:\n",
    "        with torch.no_grad():\n",
    "            feature = model.conv_reducer(patch)  # Use only the feature extractor part\n",
    "            patch_features.append(feature)\n",
    "    \n",
    "    # Combine patch features\n",
    "    combined = torch.cat(patch_features, dim=1)\n",
    "    return combined\n",
    "```\n",
    "\n",
    "## Technique 2: Advanced PyTorch Memory Management\n",
    "\n",
    "```python\n",
    "# Set stricter memory limits to avoid OOM\n",
    "torch.cuda.set_per_process_memory_fraction(0.7)  # Use only 70% of available GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Use custom CUDA allocator settings\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb=32,garbage_collection_threshold=0.6'\n",
    "\n",
    "# Enable anomaly detection for better error messages\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "```\n",
    "\n",
    "## Technique 3: Ultra-Efficient Data Processing\n",
    "\n",
    "1. Use on-the-fly image loading with caching\n",
    "2. Implement lazy dataset that loads images only when needed\n",
    "3. Compress images during processing\n",
    "\n",
    "```python\n",
    "class MemoryEfficientImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, cache_size=100):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.cache = {}\n",
    "        self.cache_size = cache_size\n",
    "        \n",
    "        # Build index of samples without loading images\n",
    "        for class_idx, class_name in enumerate(os.listdir(root_dir)):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    if os.path.isfile(img_path):\n",
    "                        self.samples.append((img_path, class_idx))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        # Check cache first\n",
    "        if img_path in self.cache:\n",
    "            img = self.cache[img_path]\n",
    "        else:\n",
    "            # Load image\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            # Cache management - limit size\n",
    "            if len(self.cache) >= self.cache_size:\n",
    "                # Remove random item from cache\n",
    "                key_to_remove = next(iter(self.cache))\n",
    "                del self.cache[key_to_remove]\n",
    "            \n",
    "            # Add to cache\n",
    "            self.cache[img_path] = img\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n",
    "```\n",
    "\n",
    "## Technique 4: Layer-by-Layer Training\n",
    "\n",
    "Train the model in stages to reduce peak memory usage:\n",
    "\n",
    "1. Train only the convolutional features first\n",
    "2. Freeze the features and train the binary network\n",
    "3. Fine-tune the entire model with reduced learning rate\n",
    "\n",
    "## Technique 5: Use TorchScript or ONNX for Inference\n",
    "\n",
    "Convert the model to a more memory-efficient format for inference:\n",
    "\n",
    "```python\n",
    "# TorchScript conversion\n",
    "scripted_model = torch.jit.script(model)\n",
    "\n",
    "# Or ONNX export\n",
    "dummy_input = torch.randn(1, 3, 224, 224, device=device)\n",
    "torch.onnx.export(model, dummy_input, \"bnn_224x224.onnx\")\n",
    "```\n",
    "\n",
    "## Technique 6: Memory Profiling and Optimization\n",
    "\n",
    "Use memory profiling to identify bottlenecks:\n",
    "\n",
    "```python\n",
    "# Memory profiling example\n",
    "from torch.utils.profiler import profile, record_function\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "             profile_memory=True, record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(inputs)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_memory_usage\", row_limit=10))\n",
    "```\n",
    "\n",
    "The results will help you identify exactly which operations are consuming the most memory so you can optimize them specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9166ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultimate Memory-Optimized CNN-BNN Hybrid Model for 224x224 Images\n",
    "\n",
    "class ConvBNN224x224(nn.Module):\n",
    "    \"\"\"\n",
    "    Ultra memory-efficient CNN-BNN hybrid model specifically for 224x224 images.\n",
    "    Uses a combination of techniques to minimize memory usage while preserving full resolution.\n",
    "    \n",
    "    Key memory optimization techniques:\n",
    "    1. Depth-wise separable convolutions to reduce parameters\n",
    "    2. Progressive feature reduction\n",
    "    3. Gradient checkpointing on all heavy layers\n",
    "    4. Binary activations in later stages\n",
    "    5. Minimal fully connected layers\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super(ConvBNN224x224, self).__init__()\n",
    "        \n",
    "        # Import torch utils for checkpointing\n",
    "        if hasattr(torch, 'utils') and hasattr(torch.utils, 'checkpoint'):\n",
    "            self.use_checkpointing = True\n",
    "            print(\"Gradient checkpointing enabled for memory efficiency\")\n",
    "        else:\n",
    "            self.use_checkpointing = False\n",
    "            print(\"Gradient checkpointing not available in this PyTorch version\")\n",
    "        \n",
    "        # Memory-efficient convolutional architecture\n",
    "        self.features = nn.Sequential(\n",
    "            # Stage 1: Initial feature extraction (224x224 -> 112x112)\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Stage 2: Depthwise separable block 1 (112x112 -> 56x56)\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1, groups=16, bias=False),  # Depthwise\n",
    "            nn.Conv2d(16, 32, kernel_size=1, bias=False),  # Pointwise\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Stage 3: Depthwise separable block 2 (56x56 -> 28x28)\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32, bias=False),  # Depthwise\n",
    "            nn.Conv2d(32, 64, kernel_size=1, bias=False),  # Pointwise\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Stage 4: Depthwise separable block 3 (28x28 -> 14x14)\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, groups=64, bias=False),  # Depthwise\n",
    "            nn.Conv2d(64, 128, kernel_size=1, bias=False),  # Pointwise\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Stage 5: Final extraction (14x14 -> 7x7)\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, groups=128, bias=False),  # Depthwise\n",
    "            nn.Conv2d(128, 256, kernel_size=1, bias=False),  # Pointwise\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Stage 6: Adaptive pooling to fixed size\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        # Binary classification stage\n",
    "        self.binary_classifier = nn.Sequential(\n",
    "            # Binary layer\n",
    "            BinaryLinear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # Final classifier\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def _run_stage(self, x, stage):\n",
    "        \"\"\"Helper method to run a stage with gradient checkpointing if enabled\"\"\"\n",
    "        if self.use_checkpointing and self.training:\n",
    "            return torch.utils.checkpoint.checkpoint(stage, x)\n",
    "        return stage(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Ensure input is correct shape\n",
    "        if len(x.shape) == 2:\n",
    "            # If flattened, reshape to image format\n",
    "            x = x.view(-1, 3, 224, 224)\n",
    "        \n",
    "        # Process through feature extractor with checkpointing\n",
    "        # Split the features into chunks for more efficient checkpointing\n",
    "        modules = list(self.features.children())\n",
    "        stages = [\n",
    "            nn.Sequential(*modules[0:3]),   # Stage 1 \n",
    "            nn.Sequential(*modules[3:8]),   # Stage 2\n",
    "            nn.Sequential(*modules[8:13]),  # Stage 3\n",
    "            nn.Sequential(*modules[13:18]), # Stage 4\n",
    "            nn.Sequential(*modules[18:23]), # Stage 5\n",
    "            modules[23]                     # Stage 6 (pooling)\n",
    "        ]\n",
    "        \n",
    "        # Process through each stage with memory-efficient checkpointing\n",
    "        for stage in stages:\n",
    "            x = self._run_stage(x, stage)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Binary classification stage\n",
    "        x = self.binary_classifier(x)\n",
    "        x = binary_activation(x)  # Apply binary activation\n",
    "        \n",
    "        # Final classification\n",
    "        return self.classifier(x)\n",
    "        \n",
    "    def predict_proba(self, x):\n",
    "        \"\"\"Get class probabilities using softmax\"\"\"\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            probabilities = F.softmax(logits, dim=1)\n",
    "        return probabilities\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"Get predicted class labels\"\"\"\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "        return predictions\n",
    "\n",
    "# Create model with hyperparameter control for even more memory efficiency\n",
    "def create_memory_optimized_convbnn(num_classes, dropout_rate=0.5):\n",
    "    \"\"\"Factory function to create a memory-optimized ConvBNN model\"\"\"\n",
    "    model = ConvBNN224x224(\n",
    "        num_classes=num_classes,\n",
    "        dropout_rate=dropout_rate\n",
    "    )\n",
    "    \n",
    "    # Print model summary\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"ConvBNN224x224 Model Summary:\")\n",
    "    print(f\"- Total parameters: {total_params:,}\")\n",
    "    print(f\"- Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"- Memory-optimized for 224x224 images\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "# conv_bnn_model = create_memory_optimized_convbnn(num_classes=len(class_names)).to(device)\n",
    "# optimizer = optim.Adam(conv_bnn_model.parameters(), lr=0.001)\n",
    "# Use the same training procedure as before with this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd786cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete 224x224 Training Recipe with Extreme Memory Optimization\n",
    "# This cell provides a complete recipe for training with 224x224 images\n",
    "\n",
    "def train_with_224x224(num_samples_per_class=40):\n",
    "    \"\"\"\n",
    "    Complete recipe function to train a model with 224x224 images\n",
    "    with extreme memory optimization techniques.\n",
    "    \"\"\"\n",
    "    print(\"Starting 224x224 training recipe with extreme memory optimization...\")\n",
    "    \n",
    "    # 1. Prepare memory settings\n",
    "    memory_config_224 = {\n",
    "        'image_size': 224,  # Keep 224x224 resolution\n",
    "        'batch_size': 1,    # Minimum batch size\n",
    "        'gradient_accumulation_steps': 32,  # Aggressive accumulation\n",
    "        'gc_frequency': 1,  # Maximum garbage collection\n",
    "        'memory_efficient': True,\n",
    "        'use_mixed_precision': True,\n",
    "        'max_samples_per_class': num_samples_per_class,\n",
    "        'hidden_size': 64,  # Minimal hidden units\n",
    "    }\n",
    "    \n",
    "    print(\"\\n1. Setting memory configuration for 224x224 images...\")\n",
    "    memory_config.update(memory_config_224)\n",
    "    image_size = memory_config['image_size']  # Should be 224\n",
    "    \n",
    "    # 2. Apply aggressive CUDA memory optimizations\n",
    "    print(\"\\n2. Applying aggressive CUDA memory optimizations...\")\n",
    "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True,max_split_size_mb:32'\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.enabled = True  # Keep enabled for performance\n",
    "    \n",
    "    # Free up all memory before starting\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # 3. Define optimized data loading\n",
    "    print(\"\\n3. Creating memory-efficient data loading pipeline...\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Keep full resolution\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load data with sample limit\n",
    "    plant_dataset, class_names = load_plant_disease_dataset(\n",
    "        dataset_path,\n",
    "        image_size=224,\n",
    "        memory_efficient=True,\n",
    "        max_samples_per_class=memory_config['max_samples_per_class']\n",
    "    )\n",
    "    \n",
    "    # Create train/test split\n",
    "    total_size = len(plant_dataset)\n",
    "    test_size = int(0.2 * total_size)\n",
    "    train_size = total_size - test_size\n",
    "    train_dataset, test_dataset = random_split(plant_dataset, [train_size, test_size])\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=memory_config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=memory_config['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    print(f\"  - Training samples: {len(train_dataset)}\")\n",
    "    print(f\"  - Testing samples: {len(test_dataset)}\")\n",
    "    \n",
    "    # 4. Create optimized model\n",
    "    print(\"\\n4. Creating memory-optimized ConvBNN model for 224x224 images...\")\n",
    "    model = ConvBNN224x224(num_classes=len(class_names), dropout_rate=0.5).to(device)\n",
    "    \n",
    "    # 5. Configure training with memory optimization\n",
    "    print(\"\\n5. Configuring memory-optimized training...\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # Add weight decay\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    \n",
    "    # Training parameters\n",
    "    num_epochs = 15  # Reduced epochs for testing\n",
    "    gradient_accumulation_steps = memory_config['gradient_accumulation_steps']\n",
    "    \n",
    "    print(f\"  - Epochs: {num_epochs}\")\n",
    "    print(f\"  - Gradient accumulation: {gradient_accumulation_steps} steps\")\n",
    "    print(f\"  - Effective batch size: {memory_config['batch_size'] * gradient_accumulation_steps}\")\n",
    "    \n",
    "    # 6. Train with memory monitoring\n",
    "    print(\"\\n6. Starting memory-optimized training...\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Initial GPU memory: {torch.cuda.memory_allocated() / (1024**3):.3f} GB\")\n",
    "    \n",
    "    # Train with memory-efficient function\n",
    "    training_results = train_memory_efficient(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "        device=device,\n",
    "        scheduler=scheduler,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        memory_efficient=True,\n",
    "        gc_frequency=memory_config['gc_frequency'],\n",
    "        use_mixed_precision=memory_config['use_mixed_precision'],\n",
    "        early_stopping_patience=5\n",
    "    )\n",
    "    \n",
    "    # 7. Evaluate and save\n",
    "    print(\"\\n7. Evaluating model...\")\n",
    "    eval_results = evaluate_bnn_memory_efficient(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        class_names=class_names,\n",
    "        use_mixed_precision=memory_config['use_mixed_precision']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTraining completed successfully!\")\n",
    "    print(f\"  - Final loss: {training_results['final_loss']:.4f}\")\n",
    "    print(f\"  - Final accuracy: {training_results['final_accuracy']:.2f}%\")\n",
    "    print(f\"  - Test accuracy: {eval_results['accuracy']:.2f}%\")\n",
    "    \n",
    "    # 8. Save model\n",
    "    save_path = f\"results/convbnn_224x224_samples{num_samples_per_class}_model.pth\"\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'class_names': class_names,\n",
    "    }, save_path)\n",
    "    print(f\"\\nModel saved to {save_path}\")\n",
    "    \n",
    "    return model, training_results, eval_results\n",
    "\n",
    "# To run the complete recipe, uncomment the following line:\n",
    "# model_224, train_results_224, eval_results_224 = train_with_224x224(num_samples_per_class=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56881e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Memory Optimization Techniques for 224x224 Images\n",
    "# These techniques go beyond basic memory saving methods\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "class AdvancedMemoryOptimizer:\n",
    "    \"\"\"Class providing cutting-edge memory optimization techniques for 224x224 images\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def configure_pytorch_memory(fraction=0.8, min_block_size=32):\n",
    "        \"\"\"Configure PyTorch memory management settings\"\"\"\n",
    "        # Apply advanced CUDA memory settings\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = f'expandable_segments:True,max_split_size_mb:{min_block_size}'\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            # Limit memory fraction used\n",
    "            torch.cuda.set_per_process_memory_fraction(fraction)\n",
    "            \n",
    "            # Empty cache\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # Force garbage collection\n",
    "            gc.collect()\n",
    "            \n",
    "            # Print current memory status\n",
    "            allocated = torch.cuda.memory_allocated() / (1024 ** 3)\n",
    "            reserved = torch.cuda.memory_reserved() / (1024 ** 3)\n",
    "            print(f\"Memory status after optimization:\")\n",
    "            print(f\"- Allocated: {allocated:.3f} GB\")\n",
    "            print(f\"- Reserved: {reserved:.3f} GB\")\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(\"CUDA not available - no memory optimization applied\")\n",
    "            return False\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_tensor_compression(model):\n",
    "        \"\"\"Apply tensor compression techniques to model parameters\"\"\"\n",
    "        print(\"Applying tensor compression...\")\n",
    "        \n",
    "        # Count original parameters\n",
    "        original_params = sum(p.numel() for p in model.parameters())\n",
    "        \n",
    "        # Apply parameter quantization where possible (not on binary layers)\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "                # Skip binary layers\n",
    "                if 'binary' not in name.lower():\n",
    "                    # Convert to float16 (half precision)\n",
    "                    module.weight.data = module.weight.data.half().float()\n",
    "                    if module.bias is not None:\n",
    "                        module.bias.data = module.bias.data.half().float()\n",
    "        \n",
    "        # Force single precision for BatchNorm to avoid training issues\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, torch.nn.BatchNorm1d) or isinstance(m, torch.nn.BatchNorm2d):\n",
    "                m.float()\n",
    "        \n",
    "        print(f\"Tensor compression applied to non-binary layers\")\n",
    "        print(f\"Original parameter count: {original_params:,}\")\n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_patch_dataset_loader(dataset, image_size=224, patch_size=112, batch_size=4):\n",
    "        \"\"\"Create a dataset that processes images as patches to save memory\"\"\"\n",
    "        from torch.utils.data import Dataset, DataLoader\n",
    "        \n",
    "        class PatchDataset(Dataset):\n",
    "            def __init__(self, original_dataset, patch_size=112, stride=56, transforms=None):\n",
    "                self.dataset = original_dataset\n",
    "                self.patch_size = patch_size\n",
    "                self.stride = stride\n",
    "                self.transforms = transforms\n",
    "                self.patch_indices = []\n",
    "                \n",
    "                # For each image, pre-compute patch locations\n",
    "                for img_idx in range(len(self.dataset)):\n",
    "                    # Assuming each image is square with size image_size\n",
    "                    for y in range(0, image_size - patch_size + 1, stride):\n",
    "                        for x in range(0, image_size - patch_size + 1, stride):\n",
    "                            self.patch_indices.append((img_idx, y, x))\n",
    "                \n",
    "                print(f\"Created patch dataset with {len(self.patch_indices)} patches from {len(self.dataset)} images\")\n",
    "                print(f\"- Patch size: {patch_size}x{patch_size}\")\n",
    "                print(f\"- Stride: {stride}\")\n",
    "                \n",
    "            def __len__(self):\n",
    "                return len(self.patch_indices)\n",
    "                \n",
    "            def __getitem__(self, idx):\n",
    "                img_idx, y, x = self.patch_indices[idx]\n",
    "                img, label = self.dataset[img_idx]\n",
    "                \n",
    "                # Extract patch - handle both tensor and PIL image cases\n",
    "                if isinstance(img, torch.Tensor):\n",
    "                    if len(img.shape) == 3:  # C,H,W format\n",
    "                        patch = img[:, y:y+self.patch_size, x:x+self.patch_size]\n",
    "                    else:  # Assume it's already flattened\n",
    "                        patch = img  # Can't extract patch from flattened image\n",
    "                else:\n",
    "                    # Assume PIL image\n",
    "                    patch = img.crop((x, y, x+self.patch_size, y+self.patch_size))\n",
    "                    if self.transforms:\n",
    "                        patch = self.transforms(patch)\n",
    "                \n",
    "                return patch, label\n",
    "        \n",
    "        # Create patch dataset and loader\n",
    "        patch_dataset = PatchDataset(dataset, patch_size=patch_size)\n",
    "        patch_loader = DataLoader(\n",
    "            patch_dataset, \n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=False\n",
    "        )\n",
    "        \n",
    "        return patch_loader\n",
    "    \n",
    "    @staticmethod\n",
    "    def freeze_early_layers(model, freeze_fraction=0.7):\n",
    "        \"\"\"Freeze early layers of the model to reduce memory usage during training\"\"\"\n",
    "        # Get all parameters\n",
    "        params = list(model.named_parameters())\n",
    "        \n",
    "        # Calculate how many parameters to freeze\n",
    "        freeze_count = int(len(params) * freeze_fraction)\n",
    "        \n",
    "        # Freeze early layers\n",
    "        frozen_params = 0\n",
    "        for name, param in params[:freeze_count]:\n",
    "            param.requires_grad = False\n",
    "            frozen_params += param.numel()\n",
    "        \n",
    "        # Print status\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"Layer freezing applied:\")\n",
    "        print(f\"- Total parameters: {total_params:,}\")\n",
    "        print(f\"- Frozen parameters: {frozen_params:,} ({frozen_params/total_params*100:.1f}%)\")\n",
    "        print(f\"- Trainable parameters: {trainable_params:,} ({trainable_params/total_params*100:.1f}%)\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def optimize_training_loop(model, train_loader, criterion, optimizer, device, num_epochs=10):\n",
    "        \"\"\"Highly optimized training loop with extreme memory efficiency for 224x224 images\"\"\"\n",
    "        # Import all needed modules inside function to avoid memory leaks\n",
    "        import torch\n",
    "        import time\n",
    "        import gc\n",
    "        from torch.cuda.amp import autocast, GradScaler\n",
    "        \n",
    "        # Initialize scaler for mixed precision\n",
    "        scaler = GradScaler()\n",
    "        \n",
    "        # Track metrics\n",
    "        history = []\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_start = time.time()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            # Set to train mode\n",
    "            model.train()\n",
    "            \n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Process batches\n",
    "            for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "                # Move to device\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                # Forward with mixed precision\n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                \n",
    "                # Backward with gradient scaling\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Update metrics\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "                \n",
    "                # Aggressive memory cleanup after each batch\n",
    "                del inputs, outputs, predicted\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                \n",
    "                # Print progress\n",
    "                if batch_idx % 10 == 0:\n",
    "                    print(f\"Epoch {epoch+1}/{num_epochs} | Batch {batch_idx+1}/{len(train_loader)} | \"\n",
    "                          f\"Loss: {loss.item():.4f}\")\n",
    "            \n",
    "            # Calculate epoch metrics\n",
    "            epoch_loss = running_loss / len(train_loader)\n",
    "            epoch_acc = 100.0 * correct / total\n",
    "            epoch_time = time.time() - epoch_start\n",
    "            \n",
    "            # Record history\n",
    "            history.append({\n",
    "                'epoch': epoch + 1,\n",
    "                'loss': epoch_loss,\n",
    "                'accuracy': epoch_acc,\n",
    "                'time': epoch_time\n",
    "            })\n",
    "            \n",
    "            # Print epoch summary\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {epoch_loss:.4f} | \"\n",
    "                  f\"Accuracy: {epoch_acc:.2f}% | Time: {epoch_time:.2f}s\")\n",
    "            \n",
    "            # Clean up memory at epoch end\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        return history\n",
    "\n",
    "# Example usage of advanced memory techniques:\n",
    "# 1. Configure PyTorch memory\n",
    "# optimizer = AdvancedMemoryOptimizer()\n",
    "# optimizer.configure_pytorch_memory(fraction=0.7)\n",
    "\n",
    "# 2. Create or load your model\n",
    "# model = ConvBNN224x224(num_classes=len(class_names)).to(device)\n",
    "\n",
    "# 3. Apply tensor compression\n",
    "# model = optimizer.apply_tensor_compression(model)\n",
    "\n",
    "# 4. Freeze early layers\n",
    "# model = optimizer.freeze_early_layers(model, freeze_fraction=0.7)\n",
    "\n",
    "# 5. Create patch-based dataset loader (optional)\n",
    "# patch_loader = optimizer.create_patch_dataset_loader(train_dataset, patch_size=112)\n",
    "\n",
    "# 6. Use the optimized training loop\n",
    "# history = optimizer.optimize_training_loop(model, train_loader, criterion, optimizer, device, num_epochs=10)\n",
    "\n",
    "print(\"Advanced memory optimization techniques loaded and ready to use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f52e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction Pipeline for 224x224 Images\n",
    "# This cell provides a complete pipeline to extract features from 224x224 images\n",
    "# and train a lightweight BNN on those features\n",
    "\n",
    "class FeatureExtractionPipeline:\n",
    "    \"\"\"Complete pipeline for memory-efficient feature extraction and BNN training for 224x224 images\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_path, batch_size=4, num_workers=0, feature_dim=1280, feature_save_dir='features'):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.feature_dim = feature_dim\n",
    "        self.feature_save_dir = feature_save_dir\n",
    "        \n",
    "        # Create directory for saving features\n",
    "        os.makedirs(feature_save_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize state\n",
    "        self.feature_extractor = None\n",
    "        self.train_dataset = None\n",
    "        self.test_dataset = None\n",
    "        self.class_names = None\n",
    "        self.train_features = None\n",
    "        self.test_features = None\n",
    "        self.train_labels = None\n",
    "        self.test_labels = None\n",
    "        \n",
    "        print(f\"Feature extraction pipeline initialized\")\n",
    "        print(f\"Features will be saved to {os.path.abspath(feature_save_dir)}\")\n",
    "    \n",
    "    def setup_data(self, max_samples_per_class=None, image_size=224):\n",
    "        \"\"\"Load and prepare the image dataset without loading all images into memory\"\"\"\n",
    "        from torchvision import datasets, transforms\n",
    "        \n",
    "        # Define transforms\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Load dataset without loading all images\n",
    "        full_dataset = datasets.ImageFolder(root=self.dataset_path, transform=transform)\n",
    "        self.class_names = full_dataset.classes\n",
    "        \n",
    "        # Limit samples per class if specified\n",
    "        if max_samples_per_class is not None:\n",
    "            class_indices = {}\n",
    "            for idx, (_, class_idx) in enumerate(full_dataset.samples):\n",
    "                if class_idx not in class_indices:\n",
    "                    class_indices[class_idx] = []\n",
    "                if len(class_indices[class_idx]) < max_samples_per_class:\n",
    "                    class_indices[class_idx].append(idx)\n",
    "            \n",
    "            # Flatten indices list\n",
    "            limited_indices = [idx for indices in class_indices.values() for idx in indices]\n",
    "            from torch.utils.data import Subset\n",
    "            full_dataset = Subset(full_dataset, limited_indices)\n",
    "            print(f\"Dataset limited to {max_samples_per_class} samples per class ({len(limited_indices)} total)\")\n",
    "        \n",
    "        # Split into train/test\n",
    "        from torch.utils.data import random_split\n",
    "        test_size = int(0.2 * len(full_dataset))\n",
    "        train_size = len(full_dataset) - test_size\n",
    "        train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "        \n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        \n",
    "        print(f\"Dataset prepared with {len(train_dataset)} training and {len(test_dataset)} test samples\")\n",
    "        print(f\"Classes: {self.class_names}\")\n",
    "        \n",
    "        return train_dataset, test_dataset\n",
    "    \n",
    "    def create_feature_extractor(self, model_name='mobilenet_v2'):\n",
    "        \"\"\"Create a feature extractor for 224x224 images\"\"\"\n",
    "        import torchvision.models as models\n",
    "        \n",
    "        print(f\"Creating feature extractor using {model_name}...\")\n",
    "        \n",
    "        if model_name == 'mobilenet_v2':\n",
    "            # MobileNetV2 is very memory efficient\n",
    "            model = models.mobilenet_v2(pretrained=True)\n",
    "            # Remove classifier to get features\n",
    "            feature_extractor = torch.nn.Sequential(*list(model.features))\n",
    "            self.feature_dim = 1280  # MobileNetV2 produces 1280-dim features\n",
    "            \n",
    "        elif model_name == 'efficientnet_b0':\n",
    "            # EfficientNet is also memory efficient\n",
    "            model = models.efficientnet_b0(pretrained=True)\n",
    "            # Remove classifier to get features\n",
    "            feature_extractor = torch.nn.Sequential(*list(model.features))\n",
    "            self.feature_dim = 1280  # EfficientNet-B0 produces 1280-dim features\n",
    "            \n",
    "        elif model_name == 'mobilenet_v3_small':\n",
    "            # Even more memory efficient\n",
    "            model = models.mobilenet_v3_small(pretrained=True)\n",
    "            # Remove classifier to get features\n",
    "            feature_extractor = torch.nn.Sequential(*list(model.features))\n",
    "            self.feature_dim = 576  # MobileNetV3-Small produces 576-dim features\n",
    "        \n",
    "        # Freeze the feature extractor\n",
    "        for param in feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Move to device\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        feature_extractor = feature_extractor.to(device)\n",
    "        feature_extractor.eval()\n",
    "        \n",
    "        self.feature_extractor = feature_extractor\n",
    "        \n",
    "        print(f\"Feature extractor created using {model_name}, output dimension: {self.feature_dim}\")\n",
    "        return feature_extractor\n",
    "    \n",
    "    def extract_and_save_features(self, split='both', force_recompute=False):\n",
    "        \"\"\"Extract features from images and save to disk to save memory during training\"\"\"\n",
    "        import torch\n",
    "        from torch.utils.data import DataLoader\n",
    "        import os\n",
    "        import time\n",
    "        import numpy as np\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Check if feature extractor exists\n",
    "        if self.feature_extractor is None:\n",
    "            print(\"Feature extractor not found, creating one...\")\n",
    "            self.create_feature_extractor()\n",
    "        \n",
    "        # Define function to extract features from a dataset\n",
    "        def extract_from_dataset(dataset, name):\n",
    "            # Check if features already exist\n",
    "            features_file = os.path.join(self.feature_save_dir, f\"{name}_features.pt\")\n",
    "            labels_file = os.path.join(self.feature_save_dir, f\"{name}_labels.pt\")\n",
    "            \n",
    "            if os.path.exists(features_file) and os.path.exists(labels_file) and not force_recompute:\n",
    "                print(f\"Loading pre-computed {name} features...\")\n",
    "                features = torch.load(features_file)\n",
    "                labels = torch.load(labels_file)\n",
    "                print(f\"Loaded features shape: {features.shape}\")\n",
    "                return features, labels\n",
    "            \n",
    "            # Create dataloader\n",
    "            loader = DataLoader(\n",
    "                dataset, \n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=self.num_workers,\n",
    "                pin_memory=False\n",
    "            )\n",
    "            \n",
    "            # Initialize storage\n",
    "            all_features = []\n",
    "            all_labels = []\n",
    "            \n",
    "            # Extract features\n",
    "            print(f\"Extracting features from {len(dataset)} {name} images...\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for i, (images, labels) in enumerate(loader):\n",
    "                    if i % 5 == 0:\n",
    "                        print(f\"Processing batch {i+1}/{len(loader)}...\")\n",
    "                    \n",
    "                    # Move to device\n",
    "                    images = images.to(device)\n",
    "                    \n",
    "                    # Extract features\n",
    "                    features = self.feature_extractor(images)\n",
    "                    \n",
    "                    # Global average pooling\n",
    "                    features = torch.nn.functional.adaptive_avg_pool2d(features, (1, 1))\n",
    "                    features = features.view(features.size(0), -1)\n",
    "                    \n",
    "                    # Store\n",
    "                    all_features.append(features.cpu())\n",
    "                    all_labels.append(labels)\n",
    "                    \n",
    "                    # Clean up\n",
    "                    del images, features\n",
    "                    torch.cuda.empty_cache()\n",
    "            \n",
    "            # Concatenate\n",
    "            all_features = torch.cat(all_features, dim=0)\n",
    "            all_labels = torch.cat(all_labels, dim=0)\n",
    "            \n",
    "            # Save to disk\n",
    "            torch.save(all_features, features_file)\n",
    "            torch.save(all_labels, labels_file)\n",
    "            \n",
    "            print(f\"{name} features extracted in {time.time() - start_time:.2f}s\")\n",
    "            print(f\"Feature shape: {all_features.shape}\")\n",
    "            print(f\"Features saved to {features_file}\")\n",
    "            \n",
    "            return all_features, all_labels\n",
    "        \n",
    "        # Extract features based on specified split\n",
    "        if split == 'both' or split == 'train':\n",
    "            self.train_features, self.train_labels = extract_from_dataset(self.train_dataset, 'train')\n",
    "            \n",
    "        if split == 'both' or split == 'test':\n",
    "            self.test_features, self.test_labels = extract_from_dataset(self.test_dataset, 'test')\n",
    "            \n",
    "        return self.train_features, self.train_labels, self.test_features, self.test_labels\n",
    "    \n",
    "    def create_feature_dataloaders(self):\n",
    "        \"\"\"Create dataloaders from the extracted features\"\"\"\n",
    "        from torch.utils.data import TensorDataset, DataLoader\n",
    "        \n",
    "        # Check if features are extracted\n",
    "        if self.train_features is None or self.test_features is None:\n",
    "            self.extract_and_save_features()\n",
    "        \n",
    "        # Create TensorDatasets\n",
    "        train_dataset = TensorDataset(self.train_features, self.train_labels)\n",
    "        test_dataset = TensorDataset(self.test_features, self.test_labels)\n",
    "        \n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.batch_size * 4,  # Can use larger batch size with features\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=False\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.batch_size * 4,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=False\n",
    "        )\n",
    "        \n",
    "        print(f\"Feature DataLoaders created:\")\n",
    "        print(f\"- Train: {len(train_loader)} batches\")\n",
    "        print(f\"- Test: {len(test_loader)} batches\")\n",
    "        \n",
    "        return train_loader, test_loader\n",
    "    \n",
    "    def create_feature_classifier(self, hidden_size=128, binary=True):\n",
    "        \"\"\"Create a binary neural network to classify the extracted features\"\"\"\n",
    "        # Create a small BNN for feature classification\n",
    "        if binary:\n",
    "            # Binary Neural Network\n",
    "            class FeatureBNN(torch.nn.Module):\n",
    "                def __init__(self, feature_dim, hidden_size, num_classes):\n",
    "                    super(FeatureBNN, self).__init__()\n",
    "                    self.fc1 = BinaryLinear(feature_dim, hidden_size)\n",
    "                    self.bn1 = torch.nn.BatchNorm1d(hidden_size)\n",
    "                    self.fc2 = torch.nn.Linear(hidden_size, num_classes)\n",
    "                    \n",
    "                def forward(self, x):\n",
    "                    x = self.fc1(x)\n",
    "                    x = binary_activation(x)\n",
    "                    x = self.bn1(x)\n",
    "                    x = self.fc2(x)\n",
    "                    return x\n",
    "                \n",
    "            model = FeatureBNN(self.feature_dim, hidden_size, len(self.class_names))\n",
    "            print(\"Binary Neural Network classifier created for features\")\n",
    "        else:\n",
    "            # Standard Neural Network\n",
    "            model = torch.nn.Sequential(\n",
    "                torch.nn.Linear(self.feature_dim, hidden_size),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.BatchNorm1d(hidden_size),\n",
    "                torch.nn.Dropout(0.5),\n",
    "                torch.nn.Linear(hidden_size, len(self.class_names))\n",
    "            )\n",
    "            print(\"Standard Neural Network classifier created for features\")\n",
    "        \n",
    "        # Move to device\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = model.to(device)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train_feature_classifier(self, model, train_loader, test_loader, num_epochs=20, lr=0.001):\n",
    "        \"\"\"Train a classifier on the extracted features\"\"\"\n",
    "        import torch.optim as optim\n",
    "        from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Loss and optimizer\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "        \n",
    "        # Training loop\n",
    "        print(f\"Training feature classifier for {num_epochs} epochs...\")\n",
    "        history = []\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for i, (features, labels) in enumerate(train_loader):\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Track metrics\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Calculate epoch metrics\n",
    "            train_loss = running_loss / len(train_loader)\n",
    "            train_acc = 100.0 * correct / total\n",
    "            \n",
    "            # Evaluate\n",
    "            model.eval()\n",
    "            test_loss = 0.0\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for features, labels in test_loader:\n",
    "                    features, labels = features.to(device), labels.to(device)\n",
    "                    outputs = model(features)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    test_loss += loss.item()\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    test_total += labels.size(0)\n",
    "                    test_correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Calculate test metrics\n",
    "            test_loss = test_loss / len(test_loader)\n",
    "            test_acc = 100.0 * test_correct / test_total\n",
    "            \n",
    "            # Update scheduler\n",
    "            scheduler.step(test_loss)\n",
    "            \n",
    "            # Record history\n",
    "            history.append({\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'train_acc': train_acc,\n",
    "                'test_loss': test_loss,\n",
    "                'test_acc': test_acc,\n",
    "                'lr': optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "            \n",
    "            # Print progress\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "                  f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "        \n",
    "        print(\"Training complete!\")\n",
    "        return history\n",
    "\n",
    "# Example usage of feature extraction pipeline:\n",
    "# pipeline = FeatureExtractionPipeline(dataset_path)\n",
    "# pipeline.setup_data(max_samples_per_class=50)\n",
    "# pipeline.create_feature_extractor('mobilenet_v3_small')\n",
    "# pipeline.extract_and_save_features()\n",
    "# train_loader, test_loader = pipeline.create_feature_dataloaders()\n",
    "# model = pipeline.create_feature_classifier()\n",
    "# history = pipeline.train_feature_classifier(model, train_loader, test_loader)\n",
    "\n",
    "print(\"Feature extraction pipeline loaded and ready to use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5509090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultimate Memory-Optimized Training Recipe for 224x224 Images\n",
    "# This cell provides a complete solution for training BNNs with 224x224 images\n",
    "# with the most advanced memory optimization techniques\n",
    "\n",
    "def train_memory_optimized_bnn_224x224(num_samples_per_class=50, \n",
    "                                      num_epochs=15, \n",
    "                                      optimization_level='extreme'):\n",
    "    \"\"\"\n",
    "    Complete recipe for training a memory-optimized BNN on 224x224 images.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    num_samples_per_class : int\n",
    "        Number of samples per class to use (limit dataset size)\n",
    "    num_epochs : int\n",
    "        Number of training epochs\n",
    "    optimization_level : str\n",
    "        'moderate', 'high', or 'extreme' memory optimization\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    model : trained model\n",
    "    history : training history\n",
    "    eval_results : evaluation results\n",
    "    \"\"\"\n",
    "    import time\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader, random_split\n",
    "    import os\n",
    "    import gc\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ULTIMATE MEMORY-OPTIMIZED BNN TRAINING FOR 224x224 IMAGES\")\n",
    "    print(f\"Optimization level: {optimization_level}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # 1. Apply system-level memory optimization\n",
    "    print(\"\\n[1/7] Applying system-level memory optimization...\")\n",
    "    \n",
    "    # Create memory optimizer\n",
    "    memory_optimizer = AdvancedMemoryOptimizer()\n",
    "    \n",
    "    # Configure PyTorch memory settings based on optimization level\n",
    "    if optimization_level == 'extreme':\n",
    "        memory_fraction = 0.7\n",
    "        block_size = 32\n",
    "    elif optimization_level == 'high':\n",
    "        memory_fraction = 0.8\n",
    "        block_size = 16\n",
    "    else:  # moderate\n",
    "        memory_fraction = 0.9\n",
    "        block_size = 32\n",
    "        \n",
    "    memory_optimizer.configure_pytorch_memory(fraction=memory_fraction, min_block_size=block_size)\n",
    "    \n",
    "    # Make sure device is set correctly\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # 2. Configure memory settings\n",
    "    print(\"\\n[2/7] Configuring memory settings...\")\n",
    "    \n",
    "    # Set optimization parameters based on level\n",
    "    if optimization_level == 'extreme':\n",
    "        memory_config_224 = {\n",
    "            'image_size': 224,\n",
    "            'batch_size': 1,\n",
    "            'gradient_accumulation_steps': 32,\n",
    "            'gc_frequency': 1,\n",
    "            'memory_efficient': True,\n",
    "            'use_mixed_precision': True,\n",
    "            'max_samples_per_class': num_samples_per_class,\n",
    "            'hidden_size': 64,\n",
    "            'embedding_size': 128,\n",
    "            'num_workers': 0,\n",
    "            'pin_memory': False,\n",
    "        }\n",
    "    elif optimization_level == 'high':\n",
    "        memory_config_224 = {\n",
    "            'image_size': 224,\n",
    "            'batch_size': 2,\n",
    "            'gradient_accumulation_steps': 16,\n",
    "            'gc_frequency': 1,\n",
    "            'memory_efficient': True,\n",
    "            'use_mixed_precision': True,\n",
    "            'max_samples_per_class': num_samples_per_class,\n",
    "            'hidden_size': 128,\n",
    "            'embedding_size': 256,\n",
    "            'num_workers': 0,\n",
    "            'pin_memory': False,\n",
    "        }\n",
    "    else:  # moderate\n",
    "        memory_config_224 = {\n",
    "            'image_size': 224,\n",
    "            'batch_size': 4,\n",
    "            'gradient_accumulation_steps': 8,\n",
    "            'gc_frequency': 2,\n",
    "            'memory_efficient': True,\n",
    "            'use_mixed_precision': True,\n",
    "            'max_samples_per_class': num_samples_per_class,\n",
    "            'hidden_size': 256,\n",
    "            'embedding_size': 512,\n",
    "            'num_workers': 0,\n",
    "            'pin_memory': False,\n",
    "        }\n",
    "    \n",
    "    # Update global memory config\n",
    "    memory_config.update(memory_config_224)\n",
    "    \n",
    "    # Extract key settings\n",
    "    batch_size = memory_config['batch_size']\n",
    "    gradient_accumulation_steps = memory_config['gradient_accumulation_steps']\n",
    "    use_mixed_precision = memory_config['use_mixed_precision']\n",
    "    gc_frequency = memory_config['gc_frequency']\n",
    "    image_size = memory_config['image_size']\n",
    "    hidden_size = memory_config['hidden_size']\n",
    "    embedding_size = memory_config['embedding_size']\n",
    "    \n",
    "    print(f\"Memory configuration:\")\n",
    "    print(f\"- Image size: {image_size}x{image_size}\")\n",
    "    print(f\"- Batch size: {batch_size}\")\n",
    "    print(f\"- Gradient accumulation steps: {gradient_accumulation_steps}\")\n",
    "    print(f\"- Effective batch size: {batch_size * gradient_accumulation_steps}\")\n",
    "    print(f\"- Mixed precision: {use_mixed_precision}\")\n",
    "    print(f\"- GC frequency: {gc_frequency}\")\n",
    "    print(f\"- Max samples per class: {num_samples_per_class}\")\n",
    "    \n",
    "    # 3. Prepare dataset\n",
    "    print(\"\\n[3/7] Preparing dataset...\")\n",
    "    \n",
    "    # Create transforms with memory efficiency\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load dataset\n",
    "    if 'dataset_path' not in globals():\n",
    "        raise ValueError(\"dataset_path not defined. Please set your dataset path first.\")\n",
    "    \n",
    "    print(f\"Loading dataset from {dataset_path}...\")\n",
    "    dataset, class_names = load_plant_disease_dataset(\n",
    "        dataset_path,\n",
    "        image_size=image_size,\n",
    "        memory_efficient=True,\n",
    "        max_samples_per_class=num_samples_per_class\n",
    "    )\n",
    "    \n",
    "    # Split dataset\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset prepared:\")\n",
    "    print(f\"- Training samples: {len(train_dataset)}\")\n",
    "    print(f\"- Test samples: {len(test_dataset)}\")\n",
    "    print(f\"- Classes: {class_names}\")\n",
    "    \n",
    "    # 4. Create model with maximum memory efficiency\n",
    "    print(\"\\n[4/7] Creating memory-optimized model...\")\n",
    "    \n",
    "    # Choose model based on optimization level\n",
    "    if optimization_level == 'extreme':\n",
    "        print(\"Using ultra memory-optimized ConvBNN model for 224x224 images\")\n",
    "        model = ConvBNN224x224(\n",
    "            num_classes=len(class_names),\n",
    "            dropout_rate=0.5\n",
    "        ).to(device)\n",
    "    else:\n",
    "        print(\"Using memory-optimized BNN224x224MemoryOptimized model\")\n",
    "        model = BNN224x224MemoryOptimized(\n",
    "            input_size=3*image_size*image_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_classes=len(class_names),\n",
    "            dropout_rate=0.3\n",
    "        ).to(device)\n",
    "    \n",
    "    # Apply tensor compression if in extreme mode\n",
    "    if optimization_level == 'extreme':\n",
    "        model = memory_optimizer.apply_tensor_compression(model)\n",
    "    \n",
    "    # 5. Configure training\n",
    "    print(\"\\n[5/7] Configuring training...\")\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Optimizer with weight decay for regularization\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Training configuration:\")\n",
    "    print(f\"- Epochs: {num_epochs}\")\n",
    "    print(f\"- Optimizer: Adam(lr=0.001, weight_decay=1e-5)\")\n",
    "    print(f\"- Scheduler: ReduceLROnPlateau(factor=0.5, patience=2)\")\n",
    "    \n",
    "    # 6. Train the model\n",
    "    print(\"\\n[6/7] Training model...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Use memory-efficient training function\n",
    "    training_results = train_memory_efficient(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "        device=device,\n",
    "        scheduler=scheduler,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        memory_efficient=True,\n",
    "        gc_frequency=gc_frequency,\n",
    "        use_mixed_precision=use_mixed_precision,\n",
    "        early_stopping_patience=5\n",
    "    )\n",
    "    \n",
    "    # Calculate training time\n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"Training completed in {train_time:.2f} seconds\")\n",
    "    print(f\"Final loss: {training_results['final_loss']:.4f}\")\n",
    "    print(f\"Final accuracy: {training_results['final_accuracy']:.2f}%\")\n",
    "    \n",
    "    # 7. Evaluate the model\n",
    "    print(\"\\n[7/7] Evaluating model...\")\n",
    "    \n",
    "    # Use memory-efficient evaluation function\n",
    "    eval_results = evaluate_bnn_memory_efficient(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        class_names=class_names,\n",
    "        use_mixed_precision=use_mixed_precision\n",
    "    )\n",
    "    \n",
    "    print(f\"Evaluation results:\")\n",
    "    print(f\"- Test loss: {eval_results['loss']:.4f}\")\n",
    "    print(f\"- Test accuracy: {eval_results['accuracy']:.2f}%\")\n",
    "    print(f\"- Macro F1 score: {eval_results['macro_f1']:.4f}\")\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    print(\"\\nPer-class accuracy:\")\n",
    "    for class_name, acc in eval_results['class_accuracy'].items():\n",
    "        print(f\"- {class_name}: {acc:.2f}%\")\n",
    "    \n",
    "    # 8. Save the model\n",
    "    print(\"\\nSaving model...\")\n",
    "    save_dir = 'results'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    save_path = f\"{save_dir}/bnn_224x224_{timestamp}.pth\"\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'class_names': class_names,\n",
    "        'config': memory_config,\n",
    "        'training_results': training_results,\n",
    "        'eval_results': {k: v for k, v in eval_results.items() if not isinstance(v, torch.Tensor)}\n",
    "    }, save_path)\n",
    "    \n",
    "    print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TRAINING COMPLETE\")\n",
    "    print(f\"Final test accuracy: {eval_results['accuracy']:.2f}%\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return model, training_results, eval_results\n",
    "\n",
    "# To use this ultimate training recipe, uncomment the following line:\n",
    "# model, training_results, eval_results = train_memory_optimized_bnn_224x224(\n",
    "#     num_samples_per_class=50,  # Adjust based on available memory\n",
    "#     num_epochs=15,\n",
    "#     optimization_level='extreme'  # 'moderate', 'high', or 'extreme'\n",
    "# )\n",
    "\n",
    "print(\"Ultimate memory-optimized training recipe loaded and ready to use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5132e",
   "metadata": {},
   "source": [
    "# Comprehensive Memory Optimization Guide for 224x224 Images\n",
    "\n",
    "This guide provides a complete overview of all memory optimization techniques implemented in this notebook to efficiently train Binary Neural Networks with 224x224 images on limited GPU memory.\n",
    "\n",
    "## Optimization Categories\n",
    "\n",
    "### A. Data Pipeline Optimizations\n",
    "\n",
    "1. **Batch Size Reduction** \n",
    "   - Use batch_size=1 with gradient accumulation to simulate larger batches\n",
    "   - Effective batch size = batch_size × gradient_accumulation_steps\n",
    "   \n",
    "2. **Limited Dataset Size**\n",
    "   - Use max_samples_per_class to limit number of images loaded\n",
    "   - Preserve class balance while reducing memory footprint\n",
    "\n",
    "3. **Memory-Efficient Data Loading**\n",
    "   - Disabled worker threads (num_workers=0)\n",
    "   - Disabled pin_memory to reduce GPU memory overhead\n",
    "   - On-demand loading instead of preloading\n",
    "\n",
    "4. **Patch-Based Processing**\n",
    "   - Process 224×224 images as smaller patches (e.g., 112×112)\n",
    "   - Combine patch predictions for full-image classification\n",
    "   - Available via `create_patch_dataset_loader()` function\n",
    "\n",
    "5. **Feature Pre-extraction**\n",
    "   - Use lightweight pre-trained model to extract features\n",
    "   - Train BNN on extracted features, not raw images\n",
    "   - See `FeatureExtractionPipeline` class\n",
    "\n",
    "### B. Model Architecture Optimizations\n",
    "\n",
    "1. **Convolutional Feature Extraction**\n",
    "   - Replace flattened input (150,528 dims) with conv layers\n",
    "   - Reduces parameters by ~99% for same input size\n",
    "   - Implemented in `ConvBNN224x224` and `BNN224x224MemoryOptimized` classes\n",
    "\n",
    "2. **Progressive Dimensionality Reduction**\n",
    "   - Use multiple smaller steps to reduce dimensions\n",
    "   - Avoids massive dense layers that consume memory\n",
    "   - More aggressive reduction for early layers\n",
    "\n",
    "3. **Binary Weights and Activations**\n",
    "   - 1-bit weights and activations to reduce model size\n",
    "   - Memory-efficient binary operations\n",
    "   - Use `BinaryLinear` and `binary_activation` functions\n",
    "\n",
    "4. **Depthwise Separable Convolutions**\n",
    "   - Replace standard convolutions for efficiency\n",
    "   - Much lower parameter count while preserving performance\n",
    "   - Implemented in `ConvBNN224x224` model\n",
    "\n",
    "5. **Memory-Efficient Architectures**\n",
    "   - Multiple architecture options based on memory constraints\n",
    "   - MobileNetV3-Small for feature extraction\n",
    "   - Minimal fully-connected layers\n",
    "\n",
    "### C. Training Process Optimizations\n",
    "\n",
    "1. **Gradient Checkpointing**\n",
    "   - Discard intermediate activations during forward pass\n",
    "   - Recompute them during backward pass\n",
    "   - Trades computation for memory savings\n",
    "   - Implemented in `BNN224x224MemoryOptimized` model\n",
    "\n",
    "2. **Mixed Precision Training**\n",
    "   - Use FP16 for most operations\n",
    "   - GradScaler to avoid underflow\n",
    "   - Reduces memory usage by up to 50%\n",
    "\n",
    "3. **Aggressive Garbage Collection**\n",
    "   - Clear PyTorch cache after each batch\n",
    "   - Run Python's garbage collector frequently\n",
    "   - Delete unused tensors explicitly\n",
    "\n",
    "4. **Layer Freezing**\n",
    "   - Freeze early layers to reduce gradient memory\n",
    "   - Train only the final layers\n",
    "   - See `freeze_early_layers()` method\n",
    "\n",
    "5. **Tensor Compression**\n",
    "   - Use half-precision weights where possible\n",
    "   - Keep critical layers in full precision\n",
    "   - See `apply_tensor_compression()` method\n",
    "\n",
    "### D. System-Level Optimizations\n",
    "\n",
    "1. **CUDA Memory Configuration**\n",
    "   - Set PYTORCH_CUDA_ALLOC_CONF for better memory allocation\n",
    "   - Control memory fragmentation with max_split_size_mb\n",
    "   - Modify garbage collection threshold\n",
    "\n",
    "2. **Memory Limits**\n",
    "   - Set per-process memory fraction to avoid OOM errors\n",
    "   - Limit maximum memory usage to leave room for system\n",
    "   - See `configure_pytorch_memory()` method\n",
    "\n",
    "3. **CUDNN Settings**\n",
    "   - Disable benchmarking for more stable memory usage\n",
    "   - Enable deterministic algorithms\n",
    "   - Trade speed for reliability\n",
    "\n",
    "## Choosing the Right Strategy\n",
    "\n",
    "1. **For Extreme Memory Constraints:**\n",
    "   - Use `train_memory_optimized_bnn_224x224()` with 'extreme' optimization level\n",
    "   - Consider using the feature extraction pipeline\n",
    "   - Limit samples per class to 10-20\n",
    "\n",
    "2. **For Moderate Memory Constraints:**\n",
    "   - Use `train_memory_optimized_bnn_224x224()` with 'moderate' optimization level\n",
    "   - Use the `BNN224x224MemoryOptimized` model\n",
    "   - Limit samples per class to 50-100\n",
    "\n",
    "3. **For Performance with Memory Efficiency:**\n",
    "   - Use the `ConvBNN224x224` model\n",
    "   - Enable mixed precision training\n",
    "   - Use moderate batch size with gradient accumulation\n",
    "\n",
    "## Recipe for Success\n",
    "\n",
    "```python\n",
    "# 1. Configure memory settings\n",
    "memory_optimizer = AdvancedMemoryOptimizer()\n",
    "memory_optimizer.configure_pytorch_memory(fraction=0.7)\n",
    "\n",
    "# 2. Use the ultimate training recipe\n",
    "model, results, eval_results = train_memory_optimized_bnn_224x224(\n",
    "    num_samples_per_class=40,\n",
    "    num_epochs=15,\n",
    "    optimization_level='extreme'\n",
    ")\n",
    "```\n",
    "\n",
    "This comprehensive approach ensures you can train Binary Neural Networks on 224×224 images even on GPUs with limited memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
